This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
rendezvous_service_code/
  Dockerfile.rendezvous
  main.py
  requirements.txt
Dockerfile.worker
index.html
main.py
plan.md
plann_step2.md
plann_step3a.md
plann_step3b
plann_step4a
requirements.txt
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="rendezvous_service_code/requirements.txt">
fastapi>=0.111.0
uvicorn[standard]>=0.29.0 
# Using [standard] includes websockets and other useful dependencies for uvicorn.
# Check for latest stable versions if deploying much later.
</file>

<file path="index.html">
<!DOCTYPE html>
<html>
<head>
    <title>P2P UDP Chat - Worker: <span id="workerIdSpan"></span></title>
    <style>
        body { font-family: sans-serif; margin: 10px; background-color: #f4f4f4; }
        #chatbox { width: 95%; height: 300px; border: 1px solid #ccc; overflow-y: scroll; padding: 10px; background-color: #fff; margin-bottom: 10px; }
        #messageInput { width: 80%; padding: 10px; margin-right: 5px; border: 1px solid #ccc; }
        #sendButton { padding: 10px; background-color: #5cb85c; color: white; border: none; cursor: pointer; }
        #sendButton:hover { background-color: #4cae4c; }
        .message { margin-bottom: 5px; padding: 5px; border-radius: 3px; }
        .local { background-color: #d1e7dd; text-align: right; margin-left: 20%; }
        .peer { background-color: #f8d7da; text-align: left; margin-right: 20%;}
        .system { background-color: #e2e3e5; color: #555; font-style: italic; font-size: 0.9em;}
        #status { margin-top: 10px; font-size: 0.9em; color: #777; }
        #peerInfo { margin-top: 5px; font-size: 0.9em; color: #337ab7; }
        #benchmarkSection { margin-top: 20px; padding: 10px; border: 1px solid #ddd; background-color: #e9ecef; }
        #benchmarkStatus { margin-top: 5px; font-size: 0.9em; color: #198754; }
    </style>
</head>
<body>
    <h1>P2P UDP Chat - Worker: <span id="workerIdSpan"></span></h1>
    <div id="status">Connecting to local worker backend...</div>
    <div id="peerInfo">Peer: Not connected</div>
    <div id="chatbox"></div>
    <input type="text" id="messageInput" placeholder="Type message..."/>
    <button id="sendButton">Send</button>

    <div id="benchmarkSection">
        <h3>P2P UDP Throughput Benchmark</h3>
        <label for="benchmarkSize">Data Size (KB):</label>
        <input type="number" id="benchmarkSize" value="1024" min="1"/>
        <button id="startBenchmarkButton">Start Benchmark Send</button>
        <div id="benchmarkStatus">Benchmark status will appear here.</div>
    </div>

    <script>
        const workerIdSpan = document.getElementById('workerIdSpan');
        const chatbox = document.getElementById('chatbox');
        const messageInput = document.getElementById('messageInput');
        const sendButton = document.getElementById('sendButton');
        const statusDiv = document.getElementById('status');
        const peerInfoDiv = document.getElementById('peerInfo');
        const benchmarkSizeInput = document.getElementById('benchmarkSize');
        const startBenchmarkButton = document.getElementById('startBenchmarkButton');
        const benchmarkStatusDiv = document.getElementById('benchmarkStatus');

        let localUiSocket = null;
        let myWorkerId = "Unknown"; // Will be updated by backend

        function addMessage(text, type = "system", sender = "") {
            const messageDiv = document.createElement('div');
            messageDiv.classList.add('message', type);
            if (type === 'local' || type === 'peer') {
                 messageDiv.textContent = `${sender}: ${text}`;
            } else {
                 messageDiv.textContent = text;
            }
            chatbox.appendChild(messageDiv);
            chatbox.scrollTop = chatbox.scrollHeight; // Auto-scroll
        }

        function connectToLocalBackend() {
            const wsProtocol = window.location.protocol === "https:" ? "wss:" : "ws:";
            const localWsUrl = `${wsProtocol}//${window.location.host}/ui_ws`; 
            
            addMessage(`Attempting to connect to local UI WebSocket at ${localWsUrl}`, "system");
            localUiSocket = new WebSocket(localWsUrl);

            localUiSocket.onopen = function(event) {
                statusDiv.textContent = "Connected to local worker backend. Waiting for P2P link...";
                addMessage("Connection to local worker backend established.", "system");
                localUiSocket.send(JSON.stringify({type: "ui_client_hello"}));
            };

            localUiSocket.onmessage = function(event) {
                try {
                    const data = JSON.parse(event.data);
                    console.log("Message from local worker backend:", data);
                    if (data.type === "init_info") {
                        myWorkerId = data.worker_id;
                        workerIdSpan.textContent = myWorkerId.substring(0,8) + "...";
                        addMessage(`Worker ID: ${myWorkerId}`, "system");
                         if(data.p2p_peer_id) {
                            peerInfoDiv.textContent = `P2P Connected to Peer: ${data.p2p_peer_id.substring(0,8)}...`;
                            statusDiv.textContent = "P2P Link Active.";
                            startBenchmarkButton.disabled = false; // Enable benchmark when P2P is active
                        }
                    } else if (data.type === "p2p_message_received") {
                        addMessage(data.content, "peer", data.from_peer_id ? data.from_peer_id.substring(0,8)+"..." : "Peer");
                    } else if (data.type === "p2p_status_update") {
                        addMessage(`P2P Status: ${data.message}`, "system");
                        if (data.peer_id) {
                            peerInfoDiv.textContent = `P2P Connected to Peer: ${data.peer_id.substring(0,8)}...`;
                            statusDiv.textContent = "P2P Link Active.";
                            startBenchmarkButton.disabled = false; // Enable benchmark when P2P is active
                        } else {
                             peerInfoDiv.textContent = "Peer: Not connected";
                             if (!data.message.toLowerCase().includes("lost")) {
                                statusDiv.textContent = "P2P Link Inactive.";
                             }
                             startBenchmarkButton.disabled = true; // Disable benchmark if no P2P
                        }
                    } else if (data.type === "benchmark_status") { // NEW: Handle benchmark status messages
                        benchmarkStatusDiv.textContent = data.message;
                        addMessage(`Benchmark: ${data.message}`, "system");
                    } else if (data.type === "error") {
                        addMessage(`Error from backend: ${data.message}`, "system");
                    }
                } catch (e) {
                    addMessage("Received non-JSON message from backend: " + event.data, "system");
                }
            };

            localUiSocket.onclose = function(event) {
                statusDiv.textContent = "Disconnected from local worker backend. Attempting to reconnect...";
                addMessage("Connection to local worker backend closed. Retrying in 5s...", "system");
                startBenchmarkButton.disabled = true; // Disable on disconnect
                setTimeout(connectToLocalBackend, 5000);
            };

            localUiSocket.onerror = function(error) {
                statusDiv.textContent = "Error connecting to local worker backend.";
                addMessage("WebSocket error with local worker backend: " + error.message, "system");
                console.error("WebSocket Error: ", error);
            };
        }

        sendButton.onclick = function() {
            const messageText = messageInput.value;
            if (messageText && localUiSocket && localUiSocket.readyState === WebSocket.OPEN) {
                localUiSocket.send(JSON.stringify({
                    type: "send_p2p_message",
                    content: messageText
                }));
                addMessage(messageText, "local", "Me (" + (myWorkerId ? myWorkerId.substring(0,8)+"..." : "") + ")");
                messageInput.value = '';
            } else {
                addMessage("Cannot send message. Not connected to local backend or message is empty.", "system");
            }
        };
        
        startBenchmarkButton.onclick = function() {
            const sizeKb = parseInt(benchmarkSizeInput.value, 10);
            if (isNaN(sizeKb) || sizeKb <= 0) {
                addMessage("Invalid benchmark data size.", "system");
                benchmarkStatusDiv.textContent = "Invalid data size for benchmark.";
                return;
            }
            if (localUiSocket && localUiSocket.readyState === WebSocket.OPEN) {
                localUiSocket.send(JSON.stringify({
                    type: "start_benchmark_send",
                    size_kb: sizeKb
                }));
                benchmarkStatusDiv.textContent = `Benchmark initiated to send ${sizeKb} KB...`;
                addMessage(`Benchmark: Initiated send of ${sizeKb} KB.`, "system");
            } else {
                addMessage("Cannot start benchmark. Not connected to local backend.", "system");
                benchmarkStatusDiv.textContent = "Not connected to local backend.";
            }
        };

        messageInput.addEventListener("keypress", function(event) {
            if (event.key === "Enter") {
                event.preventDefault();
                sendButton.click();
            }
        });

        connectToLocalBackend();
    </script>
</body>
</html>
</file>

<file path="plan.md">
# Cloud Run with Cloud NAT: Public IP Observation Proof-of-Concept

**Project ID:** `iceberg-eli`

## Objective

This proof-of-concept demonstrates that a Google Cloud Run service, when configured with Direct VPC Egress to route all outbound traffic through a Cloud NAT gateway, will have its outbound connections to the public internet appear as originating from one of the public IP addresses assigned to the Cloud NAT gateway.

We will deploy a simple Python web application to Cloud Run. This application will call an external IP echo service and log the public IP address it observes. We will then verify this IP against the public IPs assigned to our Cloud NAT gateway.

## Prerequisites

1. **Google Cloud SDK (gcloud):** Ensure you have `gcloud` installed and authenticated.

   * Installation: [https://cloud.google.com/sdk/docs/install](https://cloud.google.com/sdk/docs/install)
   * Login: `gcloud auth login`
   * Set project: `gcloud config set project iceberg-eli`
2. **Docker:** While Cloud Build is used for building the image (Step 3), having Docker installed locally can be useful for testing.

   * Installation: [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/)
3. **APIs Enabled:** Ensure the following APIs are enabled in your `iceberg-eli` project.

   ```bash
   gcloud services enable \
       cloudbuild.googleapis.com \
       run.googleapis.com \
       compute.googleapis.com \
       artifactregistry.googleapis.com \
       iam.googleapis.com
   ```

## Files

Create a directory for this project and place the following two files inside it:

**1. `main.py`:**

```python
import os
import requests
from flask import Flask

app = Flask(__name__)

# Using a well-known public IP echo service.
IP_ECHO_SERVICE_URL = "https://api.ipify.org"

@app.route('/')
def get_my_public_ip():
    try:
        print(f"Cloud Run service 'ip-worker-service' (project: iceberg-eli) making request to: {IP_ECHO_SERVICE_URL}")
        response = requests.get(IP_ECHO_SERVICE_URL, timeout=10)
        response.raise_for_status()  # Raise an exception for HTTP errors
        
        public_ip = response.text.strip()
        
        log_message = f"The IP echo service reported this service's public IP as: {public_ip}"
        print(log_message)
        
        verification_note = (
            "VERIFICATION STEP: In the Google Cloud Console for project 'iceberg-eli', navigate to 'VPC Network' -> 'Cloud NAT'. "
            "Select the 'ip-worker-nat' gateway in the 'us-central1' region. "
            "Confirm that the IP address reported above is listed under 'NAT IP addresses' for that gateway."
        )
        print(verification_note)
        
        return f"{log_message}<br><br>{verification_note.replace(chr(10), '<br>')}", 200

    except requests.exceptions.RequestException as e:
        error_message = f"Error connecting to IP echo service: {e}"
        print(error_message)
        return error_message, 500

if __name__ == "__main__":
    if not os.environ.get("K_SERVICE"):
        port = int(os.environ.get("PORT", 8080))
        app.run(host='0.0.0.0', port=port, debug=True)
```

**2. `Dockerfile`:**

```dockerfile
FROM python:3.9-slim

WORKDIR /app

RUN pip install --no-cache-dir Flask requests gunicorn

COPY main.py .

EXPOSE 8080

ENV PORT 8080

CMD ["gunicorn", "--bind", "0.0.0.0:8080", "main:app"]
```

## Step 1: Prepare Your Google Cloud Environment

We'll set up the networking resources in the `us-central1` region for project `iceberg-eli`.

1. **Define Shell Variables (Optional, for convenience):**

   ```bash
   export PROJECT_ID="iceberg-eli"
   export REGION="us-central1"
   export VPC_NETWORK_NAME="ip-worker-vpc"
   export SUBNET_NAME="ip-worker-subnet"
   export SUBNET_CIDR="10.10.1.0/24"
   export ROUTER_NAME="ip-worker-router"
   export NAT_NAME="ip-worker-nat"
   export AR_REPO_NAME="ip-worker-repo"
   export CLOUD_RUN_SERVICE_NAME="ip-worker-service"

   gcloud config set project $PROJECT_ID
   gcloud config set compute/region $REGION
   ```

2. **Create VPC Network:**

   ```bash
   gcloud compute networks create $VPC_NETWORK_NAME \
       --project=$PROJECT_ID \
       --subnet-mode=custom \
       --mtu=1460 \
       --bgp-routing-mode=regional
   ```

3. **Create VPC Subnet:**

   ```bash
   gcloud compute networks subnets create $SUBNET_NAME \
       --project=$PROJECT_ID \
       --range=$SUBNET_CIDR \
       --network=$VPC_NETWORK_NAME \
       --region=$REGION
   ```

4. **Create Cloud Router:**

   ```bash
   gcloud compute routers create $ROUTER_NAME \
       --project=$PROJECT_ID \
       --network=$VPC_NETWORK_NAME \
       --region=$REGION
   ```

5. **Create Cloud NAT Gateway:**

   ```bash
   gcloud compute nats create $NAT_NAME \
       --project=$PROJECT_ID \
       --router=$ROUTER_NAME \
       --region=$REGION \
       --nat-custom-subnet-ip-ranges=$SUBNET_NAME \
       --nat-external-ip-pool=""
   ```

## Step 2: Build and Push the Docker Image

1. **Create Artifact Registry Repository:**

   ```bash
   gcloud artifacts repositories create $AR_REPO_NAME \
       --project=$PROJECT_ID \
       --repository-format=docker \
       --location=$REGION \
       --description="Docker repository for IP worker PoC"
   ```

2. **Grant Cloud Build permissions:**

   ```bash
   export PROJECT_NUMBER=$(gcloud projects describe $PROJECT_ID --format='value(projectNumber)')
   gcloud projects add-iam-policy-binding $PROJECT_ID \
       --member="serviceAccount:${PROJECT_NUMBER}@cloudbuild.gserviceaccount.com" \
       --role="roles/artifactregistry.writer"
   ```

3. **Build and Submit Image:**

   ```bash
   gcloud builds submit --region=$REGION --tag ${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_REPO_NAME}/${CLOUD_RUN_SERVICE_NAME}:latest
   ```

## Step 3: Deploy to Cloud Run

```bash
gcloud run deploy $CLOUD_RUN_SERVICE_NAME \
    --project=$PROJECT_ID \
    --image=${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_REPO_NAME}/${CLOUD_RUN_SERVICE_NAME}:latest \
    --platform=managed \
    --region=$REGION \
    --allow-unauthenticated \
    --vpc-egress=all-traffic \
    --network=$VPC_NETWORK_NAME \
    --subnet=$SUBNET_NAME \
    --max-instances=1
```

## Step 4: Test and Verify

1. **Get Service URL:**

   ```bash
   gcloud run services describe $CLOUD_RUN_SERVICE_NAME --project=$PROJECT_ID --platform=managed --region=$REGION --format='value(status.url)'
   ```

2. **Invoke Service:**

   ```bash
   SERVICE_URL=$(gcloud run services describe $CLOUD_RUN_SERVICE_NAME --project=$PROJECT_ID --platform=managed --region=$REGION --format='value(status.url)')
   echo "Accessing service at: $SERVICE_URL"
   curl $SERVICE_URL
   ```

3. **Check Logs and Verify NAT IP:**

   * Go to Cloud Console: Cloud Run -> `ip-worker-service` -> Logs
   * Output will include observed IP
   * Go to VPC Network -> Cloud NAT -> `ip-worker-nat` and confirm observed IP is listed

## Step 5: Cleanup (Optional)

```bash
gcloud run services delete $CLOUD_RUN_SERVICE_NAME --project=$PROJECT_ID --platform=managed --region=$REGION --quiet
gcloud compute nats delete $NAT_NAME --router=$ROUTER_NAME --project=$PROJECT_ID --region=$REGION --quiet
gcloud compute routers delete $ROUTER_NAME --project=$PROJECT_ID --region=$REGION --quiet
gcloud artifacts repositories delete $AR_REPO_NAME --project=$PROJECT_ID --location=$REGION --quiet

# Optional, be cautious
# gcloud compute networks subnets delete $SUBNET_NAME --project=$PROJECT_ID --region=$REGION --quiet
# gcloud compute networks delete $VPC_NETWORK_NAME --project=$PROJECT_ID --quiet
```

*Always double-check before deleting shared resources.*
</file>

<file path="plann_step3a.md">
## README - Step 3 (Part A): Worker UDP Endpoint Discovery and Registration

### Objective

This part focuses on enabling each Worker service to:

1.  Create and manage a local UDP socket.
2.  Utilize a public STUN (Session Traversal Utilities for NAT) server to discover its own public IP address and port mapping for this UDP socket, as created by the Cloud NAT gateway.
3.  Report this discovered public UDP endpoint (`NAT_IP:NAT_UDP_Port`) to the Rendezvous service via the existing WebSocket connection.
4.  The Rendezvous service will be updated to store this UDP endpoint information alongside the existing worker details.

This step is crucial for gathering the necessary addressing information for actual UDP hole punching between peers, which will be covered in a subsequent part.

### Prerequisites

1.  **Completion of Step 2:** Your Rendezvous Service and modified Worker Service (with WebSocket registration and health checks) should be deployed and working correctly. Workers should be registering with the Rendezvous service.
2.  **Project Setup:** `gcloud` configured for `iceberg-eli`, `us-central1` region, APIs enabled, and existing networking (VPC, Subnet, Cloud Router, Cloud NAT from Step 1) should be in place.
3.  **Understanding STUN:** Briefly, STUN helps clients discover their public IP address and the type of NAT they are behind, without requiring any special logic on the NAT device itself. We'll use a public STUN server like Google's (`stun.l.google.com:19302`).

-----

## Part 3A.1: Modifications to Rendezvous Service

The Rendezvous service needs to be updated to accept and store the UDP endpoint information from the workers.

### 3A.1.1. Shell Variables (Rendezvous Service - mostly existing)

```bash
# Dynamically get Project ID and set Region (example for us-central1)
export PROJECT_ID=$(gcloud config get-value project)
export REGION="us-central1"

export AR_RENDEZVOUS_REPO_NAME="rendezvous-repo" 
export RENDEZVOUS_SERVICE_NAME="rendezvous-service"
export RENDEZVOUS_IMAGE_TAG_V2="v_step3a" # New version tag for this step
```

### 3A.1.2. Rendezvous Service Code (`rendezvous_service_code/main.py`) Updates

```python
import asyncio
import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from typing import Dict, Tuple, Optional # Added Optional
import os
import json

app = FastAPI(title="Rendezvous Service")

# Updated storage for connected workers to include UDP endpoint info
# Format: {worker_id: {
#    "public_ip": str, "public_port": int, # From WebSocket connection (or self-reported HTTP IP)
#    "websocket": WebSocket,
#    "udp_ip": Optional[str], "udp_port": Optional[int] # Discovered via STUN by worker
# }}
connected_workers: Dict[str, Dict] = {}

@app.websocket("/ws/register/{worker_id}")
async def websocket_register_worker(websocket: WebSocket, worker_id: str):
    print(f"RENDEZVOUS_DEBUG: Attempting to register worker '{worker_id}'. Scope: {websocket.scope}") # Early debug
    await websocket.accept()
    client_host = websocket.client.host # IP from WebSocket connection
    client_port = websocket.client.port # Port from WebSocket connection
    
    print(f"Worker '{worker_id}' connecting from WebSocket endpoint: {client_host}:{client_port}")

    if worker_id in connected_workers:
        print(f"Worker '{worker_id}' re-connecting or duplicate ID detected.")
        old_ws = connected_workers[worker_id].get("websocket")
        if old_ws and hasattr(old_ws, 'client_state') and old_ws.client_state.value == 1: # WebSocketState.CONNECTED
             try:
                await old_ws.close(code=1000, reason="New connection from same worker ID")
             except Exception:
                pass 

    connected_workers[worker_id] = {
        "public_ip": client_host, 
        "public_port": client_port, 
        "websocket": websocket,
        "udp_ip": None, 
        "udp_port": None
    }
    print(f"Worker '{worker_id}' registered. WebSocket EP: {client_host}:{client_port}. Total: {len(connected_workers)}")

    try:
        while True: 
            raw_data = await websocket.receive_text()
            print(f"Received raw message from '{worker_id}': {raw_data}")
            try:
                message = json.loads(raw_data)
                msg_type = message.get("type")
                print(f"RENDEZVOUS_DEBUG: Parsed msg_type: {repr(msg_type)}")

                if msg_type == "register_public_ip":
                    new_ip = message.get("ip")
                    if new_ip and worker_id in connected_workers:
                        print(f"Worker '{worker_id}' self-reported (HTTP-based) public IP: {new_ip}. Storing as 'public_ip'.")
                        connected_workers[worker_id]["public_ip"] = new_ip 
                    elif not new_ip:
                        print(f"Worker '{worker_id}' sent register_public_ip message without an IP.")
                
                elif msg_type == "update_udp_endpoint":
                    udp_ip = message.get("udp_ip")
                    udp_port = message.get("udp_port")
                    if udp_ip and udp_port and worker_id in connected_workers:
                        connected_workers[worker_id]["udp_ip"] = udp_ip
                        connected_workers[worker_id]["udp_port"] = int(udp_port) 
                        print(f"Worker '{worker_id}' updated UDP endpoint to: {udp_ip}:{udp_port}")
                        await websocket.send_text(json.dumps({"type": "udp_endpoint_ack", "status": "success"}))
                    else:
                        print(f"Worker '{worker_id}' sent incomplete update_udp_endpoint message.")
                        await websocket.send_text(json.dumps({"type": "udp_endpoint_ack", "status": "error", "detail": "Missing IP or Port"}))
                
                elif msg_type == "echo_request":
                    payload = message.get("payload", "")
                    response_payload_dict = {
                        "type": "echo_response",
                        "original_payload": payload,
                        "processed_by_rendezvous": f"Rendezvous processed: '{payload.upper()}' for worker {worker_id}"
                    }
                    await websocket.send_text(json.dumps(response_payload_dict))
                    print(f"Sent echo_response back to worker '{worker_id}'")
                
                elif msg_type == "get_my_details":
                    if worker_id in connected_workers:
                        details = connected_workers[worker_id]
                        response_payload_dict = {
                            "type": "my_details_response",
                            "worker_id": worker_id,
                            "registered_ip": details["public_ip"],
                            "registered_port": details["public_port"],
                            "udp_ip": details.get("udp_ip"), # Include UDP info if available
                            "udp_port": details.get("udp_port"),
                            "message": "These are your details as seen by the Rendezvous service."
                        }
                        await websocket.send_text(json.dumps(response_payload_dict))
                        print(f"Sent 'my_details_response' back to worker '{worker_id}'")
                    else:
                        await websocket.send_text(json.dumps({"type": "error", "message": "Could not find your details."}))

                else:
                    print(f"Worker '{worker_id}' sent unhandled message type: {msg_type}")

            except json.JSONDecodeError:
                print(f"Worker '{worker_id}' sent non-JSON message: {raw_data}")
            except AttributeError: 
                print(f"Worker '{worker_id}' sent malformed JSON message: {raw_data}")
            except KeyError:
                 print(f"Worker '{worker_id}' no longer in connected_workers dictionary, could not process message.")

    except WebSocketDisconnect:
        print(f"Worker '{worker_id}' disconnected from WebSocket EP: {client_host}:{client_port}.")
    except Exception as e:
        print(f"Error with worker '{worker_id}' WebSocket: {e}")
    finally:
        if worker_id in connected_workers and connected_workers[worker_id]["websocket"] == websocket:
            del connected_workers[worker_id]
            print(f"Worker '{worker_id}' de-registered. Total workers: {len(connected_workers)}")

@app.get("/")
async def read_root():
    return {"message": "Rendezvous Service is running. Connect via WebSocket at /ws/register/{worker_id}"}

@app.get("/debug/list_workers")
async def list_workers():
    workers_info = {}
    for worker_id_key, data_val in list(connected_workers.items()):
        ws_object = data_val.get("websocket")
        current_client_state_value = None
        is_connected = False
        if ws_object and hasattr(ws_object, 'client_state'):
            current_client_state = ws_object.client_state
            current_client_state_value = current_client_state.value
            is_connected = (current_client_state_value == 1) 
        
        workers_info[worker_id_key] = {
            "websocket_observed_ip": data_val.get("public_ip"),
            "websocket_observed_port": data_val.get("public_port"),
            "stun_reported_udp_ip": data_val.get("udp_ip"),
            "stun_reported_udp_port": data_val.get("udp_port"),
            "websocket_connected": is_connected,
            "websocket_raw_state": current_client_state_value
        }
    return {"connected_workers_count": len(workers_info), "workers": workers_info}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=int(os.environ.get("PORT", 8080)))
```

### 3A.1.3. Rendezvous Service `requirements.txt` and `Dockerfile.rendezvous`

No changes are needed to these files from Step 2.

### 3A.1.4. Build and Re-deploy the Rendezvous Service

1.  **Build Image:**
    Use your preferred method (Cloud Build or local Docker). If using local Docker on non-amd64, use `docker buildx`:
    ```bash
    # From repo root: 
    # cd rendezvous_service_code # if commands are run from here
    docker buildx build --platform linux/amd64 -f rendezvous_service_code/Dockerfile.rendezvous -t gcr.io/$PROJECT_ID/$AR_RENDEZVOUS_REPO_NAME/$RENDEZVOUS_SERVICE_NAME:${RENDEZVOUS_IMAGE_TAG_V2} ./rendezvous_service_code --load
    docker push gcr.io/$PROJECT_ID/$AR_RENDEZVOUS_REPO_NAME/$RENDEZVOUS_SERVICE_NAME:${RENDEZVOUS_IMAGE_TAG_V2}
    ```

2.  **Re-deploy Rendezvous Service:**
    ```bash
    gcloud run deploy $RENDEZVOUS_SERVICE_NAME \
        --project=$PROJECT_ID \
        --image=gcr.io/$PROJECT_ID/$AR_RENDEZVOUS_REPO_NAME/$RENDEZVOUS_SERVICE_NAME:${RENDEZVOUS_IMAGE_TAG_V2} \
        --platform=managed \
        --region=$REGION \
        --allow-unauthenticated \
        --session-affinity \
        --min-instances=1 # Recommended to keep it warm
    ```

-----

## Part 3A.2: Modifications to Worker Service

The Worker service will now include logic to create a UDP socket, query a STUN server, and report the discovered UDP endpoint.

### 3A.2.1. Shell Variables (Worker Service - mostly existing)

```bash
# Ensure PROJECT_ID and REGION are set (as in Part 1.1)
export AR_WORKER_REPO_NAME="ip-worker-repo" 
export WORKER_SERVICE_NAME="ip-worker-service" 
export WORKER_IMAGE_TAG_V3="v_step3a" # New version tag for this step

# Ensure RENDEZVOUS_SERVICE_URL is set, e.g.:
# export RENDEZVOUS_SERVICE_URL=$(gcloud run services describe $RENDEZVOUS_SERVICE_NAME --platform managed --region $REGION --project $PROJECT_ID --format 'value(status.url)')
if [ -z "$RENDEZVOUS_SERVICE_URL" ]; then echo "Error: RENDEZVOUS_SERVICE_URL is not set."; fi
```

### 3A.2.2. Worker Service Code (`holepunch/main.py`) Updates

```python
import asyncio
import os
import uuid
import websockets
import signal
import threading
import http.server
import socketserver
import requests
import json
import socket
import stun # from pystun3
from typing import Optional

worker_id = str(uuid.uuid4())
stop_signal_received = False
udp_socket: Optional[socket.socket] = None 
discovered_udp_ip: Optional[str] = None
discovered_udp_port: Optional[int] = None

DEFAULT_STUN_HOST = "stun.l.google.com"
DEFAULT_STUN_PORT = 19302

def handle_shutdown_signal(signum, frame):
    global stop_signal_received
    print(f"Shutdown signal ({signum}) received. Worker '{worker_id}' attempting graceful shutdown.")
    stop_signal_received = True
    if udp_socket:
        try:
            udp_socket.close()
            print(f"Worker '{worker_id}': UDP socket closed.")
        except Exception as e:
            print(f"Worker '{worker_id}': Error closing UDP socket: {e}")

async def discover_udp_endpoint_and_report(websocket_conn):
    global udp_socket, discovered_udp_ip, discovered_udp_port
    
    if udp_socket is None:
        udp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        try:
            udp_socket.bind(("0.0.0.0", 0))
            source_ip, source_port = udp_socket.getsockname()
            print(f"Worker '{worker_id}': UDP socket created and bound to local {source_ip}:{source_port}")
        except Exception as e:
            print(f"Worker '{worker_id}': Error binding UDP socket: {e}. Cannot perform STUN discovery.")
            if udp_socket:
                udp_socket.close()
                udp_socket = None
            return

    stun_host = os.environ.get("STUN_HOST", DEFAULT_STUN_HOST)
    stun_port = int(os.environ.get("STUN_PORT", DEFAULT_STUN_PORT))

    print(f"Worker '{worker_id}': Our main UDP socket is bound to local {udp_socket.getsockname()[0]}:{udp_socket.getsockname()[1]}")
    print(f"Worker '{worker_id}': Attempting STUN discovery to {stun_host}:{stun_port} (pystun3 will use its own ephemeral client port)")
    
    try:
        nat_type, external_ip, external_port = stun.get_ip_info(
            stun_host=stun_host, 
            stun_port=stun_port
        )
        print(f"Worker '{worker_id}': STUN discovery result: NAT Type={nat_type}, External IP={external_ip}, External Port={external_port}")

        if external_ip and external_port:
            discovered_udp_ip = external_ip
            discovered_udp_port = external_port
            
            udp_endpoint_message = {
                "type": "update_udp_endpoint",
                "udp_ip": discovered_udp_ip,
                "udp_port": discovered_udp_port
            }
            await websocket_conn.send(json.dumps(udp_endpoint_message))
            print(f"Worker '{worker_id}': Sent discovered UDP endpoint ({discovered_udp_ip}:{discovered_udp_port}) to Rendezvous.")
        else:
            print(f"Worker '{worker_id}': STUN discovery failed to return external IP/Port.")

    except stun.StunError as e: # Catch specific pystun3 error
        print(f"Worker '{worker_id}': STUN error: {e}")
    except socket.gaierror as e: 
        print(f"Worker '{worker_id}': STUN host DNS resolution error: {e}")
    except Exception as e:
        print(f"Worker '{worker_id}': Error during STUN discovery: {type(e).__name__} - {e}")
    
async def udp_listener_task():
    global udp_socket, stop_signal_received
    if not udp_socket:
        print(f"Worker '{worker_id}': UDP socket not initialized. UDP listener cannot start.")
        return

    local_ip, local_port = udp_socket.getsockname()
    print(f"Worker '{worker_id}': Starting UDP listener on {local_ip}:{local_port}... (placeholder)")
    try:
        while not stop_signal_received:
            await asyncio.sleep(60) 
            if not stop_signal_received:
                 print(f"Worker '{worker_id}': UDP socket still open on local {local_ip}:{local_port} (placeholder listener active)")
    except asyncio.CancelledError:
        print(f"Worker '{worker_id}': UDP listener task cancelled.")
    except Exception as e:
        if not stop_signal_received: 
            print(f"Worker '{worker_id}': Error in placeholder UDP listener loop: {e}")
    finally:
        print(f"Worker '{worker_id}': UDP listener task stopped.")

async def connect_to_rendezvous(rendezvous_ws_url: str):
    global stop_signal_received, discovered_udp_ip, discovered_udp_port
    print(f"WORKER CONNECT_TO_RENDEZVOUS: Entered function for URL: {rendezvous_ws_url}. stop_signal_received={stop_signal_received}")
    print(f"Worker '{worker_id}' attempting to connect to Rendezvous: {rendezvous_ws_url}")
    
    ip_echo_service_url = "https://api.ipify.org" 
    ping_interval = float(os.environ.get("PING_INTERVAL_SEC", "25")) 
    ping_timeout = float(os.environ.get("PING_TIMEOUT_SEC", "25")) 

    while not stop_signal_received:
        try:
            async with websockets.connect(
                rendezvous_ws_url,
                ping_interval=ping_interval,
                ping_timeout=ping_timeout,
            ) as websocket:
                print(f"WORKER '{worker_id}' connected to Rendezvous. Type: {type(websocket)}, Dir: {dir(websocket)}")
                print(f"Worker '{worker_id}' connected to Rendezvous via WebSocket.")

                try:
                    print(f"Worker '{worker_id}' fetching its HTTP-based public IP from {ip_echo_service_url}...")
                    response = requests.get(ip_echo_service_url, timeout=10)
                    response.raise_for_status()
                    http_public_ip = response.text.strip()
                    print(f"Worker '{worker_id}' identified HTTP-based public IP as: {http_public_ip}")
                    await websocket.send(json.dumps({"type": "register_public_ip", "ip": http_public_ip}))
                    print(f"Worker '{worker_id}' sent HTTP-based public IP to Rendezvous.")
                except requests.exceptions.RequestException as e:
                    print(f"Worker '{worker_id}': Error fetching/sending HTTP-based public IP: {e}.")

                await discover_udp_endpoint_and_report(websocket)

                listener_task_handle = None
                if udp_socket and discovered_udp_ip and discovered_udp_port:
                    listener_task_handle = asyncio.create_task(udp_listener_task())
                
                print(f"WORKER '{worker_id}': Entering main WebSocket receive loop...")
                while not stop_signal_received:
                    try:
                        message_raw = await asyncio.wait_for(websocket.recv(), timeout=max(30.0, ping_interval + ping_timeout + 10))
                        print(f"RAW Received from Rendezvous (WebSocket): {message_raw}")
                        try:
                            message_data = json.loads(message_raw)
                            msg_type = message_data.get("type")
                            if msg_type == "udp_endpoint_ack":
                                print(f"Received UDP endpoint ack from Rendezvous: {message_data.get('status')}")
                            elif msg_type == "echo_response": 
                                print(f"Echo Response from Rendezvous: {message_data.get('processed_by_rendezvous')}")
                            else:
                                print(f"Received unhandled message type from Rendezvous: {msg_type}")
                        except json.JSONDecodeError:
                            print(f"Received non-JSON message from Rendezvous: {message_raw}")
                    except asyncio.TimeoutError:
                        pass 
                    except websockets.exceptions.ConnectionClosed:
                        print(f"Worker '{worker_id}': Rendezvous WebSocket connection closed by server.")
                        break 
                print(f"WORKER '{worker_id}': Exited main WebSocket receive loop.")
                
                if listener_task_handle and not listener_task_handle.done():
                    listener_task_handle.cancel()
                    try: await listener_task_handle
                    except asyncio.CancelledError: print(f"Worker '{worker_id}': UDP listener task explicitly cancelled.")
            
        except websockets.exceptions.ConnectionClosedOK:
            print(f"Worker '{worker_id}': Rendezvous WebSocket connection closed gracefully by server.")
        except websockets.exceptions.InvalidURI:
            print(f"Worker '{worker_id}': Invalid Rendezvous WebSocket URI: {rendezvous_ws_url}. Exiting.")
            return 
        except ConnectionRefusedError:
            print(f"Worker '{worker_id}': Connection to Rendezvous refused. Retrying in 10 seconds...")
        except Exception as e: 
            print(f"Worker '{worker_id}': Error in WebSocket connect_to_rendezvous outer loop: {e}. Retrying in 10s...")
        
        if not stop_signal_received:
            await asyncio.sleep(10) 
        else:
            break 

    print(f"Worker '{worker_id}' has stopped WebSocket connection attempts.")

def start_healthcheck_http_server():
    class _Handler(http.server.BaseHTTPRequestHandler):
        def do_GET(self): self.send_response(200); self.send_header("Content-Type","text/plain"); self.end_headers(); self.wfile.write(b"OK")
        def log_message(self, format, *args): return
    port = int(os.environ.get("PORT", 8080))
    httpd = socketserver.TCPServer(("0.0.0.0", port), _Handler)
    threading.Thread(target=httpd.serve_forever, daemon=True).start()
    print(f"Health-check HTTP server listening on 0.0.0.0:{port}")

start_healthcheck_http_server()
print("HEALTHCHECK SERVER STARTED --- WORKER MAIN SCRIPT CONTINUING...")

if __name__ == "__main__":
    print("WORKER SCRIPT: Inside __main__ block.")
    rendezvous_base_url = os.environ.get("RENDEZVOUS_SERVICE_URL")
    if not rendezvous_base_url:
        print("Error: RENDEZVOUS_SERVICE_URL environment variable not set. Exiting.")
        exit(1)

    if rendezvous_base_url.startswith("http://"):
        rendezvous_ws_url_constructed = rendezvous_base_url.replace("http://", "ws://", 1)
    elif rendezvous_base_url.startswith("https://"):
        rendezvous_ws_url_constructed = rendezvous_base_url.replace("https://", "wss://", 1)
    else:
        rendezvous_ws_url_constructed = rendezvous_base_url 

    full_rendezvous_ws_url = f"{rendezvous_ws_url_constructed}/ws/register/{worker_id}"
    print(f"WORKER SCRIPT: About to call asyncio.run(connect_to_rendezvous) for URL: {full_rendezvous_ws_url}")
    
    signal.signal(signal.SIGTERM, handle_shutdown_signal)
    signal.signal(signal.SIGINT, handle_shutdown_signal)

    try:
        asyncio.run(connect_to_rendezvous(full_rendezvous_ws_url))
    except KeyboardInterrupt:
        print(f"Worker '{worker_id}' interrupted by user. Shutting down.")
    finally:
        print(f"Worker '{worker_id}' main process finished.")
        if udp_socket: 
            udp_socket.close()
            print(f"Worker '{worker_id}': UDP socket closed in __main__ finally block.")
```

### 3A.2.3. Worker Service `requirements.txt` (`holepunch/requirements.txt`)

```
websockets>=12.0
requests>=2.0.0 
pystun3>=1.1.6 
# Check for the latest stable version of pystun3
```

### 3A.2.4. Worker Service `Dockerfile.worker` (`holepunch/Dockerfile.worker`)

Make sure the CMD uses `python -u` for unbuffered output:
```dockerfile
# ... (rest of Dockerfile) ...
CMD ["python", "-u", "main.py"]
```

### 3A.2.5. Build and Re-deploy the Worker Service

1.  **Build Image:**
    (Ensure you are in the `holepunch` directory root)
    ```bash
    docker buildx build --platform linux/amd64 -f Dockerfile.worker -t gcr.io/$PROJECT_ID/$AR_WORKER_REPO_NAME/$WORKER_SERVICE_NAME:${WORKER_IMAGE_TAG_V3} . --load
    docker push gcr.io/$PROJECT_ID/$AR_WORKER_REPO_NAME/$WORKER_SERVICE_NAME:${WORKER_IMAGE_TAG_V3}
    ```

2.  **Re-deploy Worker Service:**
    ```bash
    gcloud run deploy $WORKER_SERVICE_NAME \
        --project=$PROJECT_ID \
        --image=gcr.io/$PROJECT_ID/$AR_WORKER_REPO_NAME/$WORKER_SERVICE_NAME:${WORKER_IMAGE_TAG_V3} \
        --platform=managed \
        --region=$REGION \
        --update-env-vars="RENDEZVOUS_SERVICE_URL=${RENDEZVOUS_SERVICE_URL},STUN_HOST=stun.l.google.com,STUN_PORT=19302,PING_INTERVAL_SEC=25,PING_TIMEOUT_SEC=25" \
        --vpc-egress=all-traffic \
        --network=ip-worker-vpc \
        --subnet=ip-worker-subnet \
        --min-instances=1 \
        --max-instances=2 
    ```

-----

## Part 3A.3: Verification

1.  **Deploy both services** (Rendezvous first, then Worker).
2.  **Check Worker Logs:**
      * UDP socket creation: `Worker '...' UDP socket created and bound to local ...`
      * STUN discovery attempt: `Worker '...' Attempting STUN discovery to stun.l.google.com:19302 ...`
      * STUN result: `Worker '...' STUN discovery result: NAT Type=..., External IP=X.X.X.X, External Port=Y`
      * Message sent to Rendezvous: `Worker '...' Sent discovered UDP endpoint (...) to Rendezvous.`
      * Ack received: `Received UDP endpoint ack from Rendezvous: success`
      * Placeholder UDP listener: `Worker '...' Starting UDP listener on ...` and `UDP socket still open ...`
3.  **Check Rendezvous Logs:**
      * Worker WebSocket connection.
      * Receipt of `register_public_ip`.
      * Receipt of `update_udp_endpoint` message.
      * Log showing UDP IP/port update: `Worker '...' updated UDP endpoint to: X.X.X.X:Y`
4.  **Use Rendezvous Debug Endpoint (`/debug/list_workers`):**
      * Verify `stun_reported_udp_ip` and `stun_reported_udp_port` are populated.
      * Verify `websocket_connected` is `true`.

This confirms Step 3A: workers discover and register their public UDP endpoints.
</file>

<file path="plann_step3b">
## README - Step 3 (Part B): Peer-to-Peer UDP Connection Attempt

### Objective

This part details the modifications needed to:

1.  Enable the **Rendezvous Service** to actively introduce two registered workers that have valid UDP endpoints, instructing them to attempt a P2P UDP connection with each other.
2.  Update the **Worker Service** to:
      * Handle connection initiation instructions (a "p2p\_connection\_offer") from the Rendezvous service.
      * Implement the client-side logic for UDP hole punching:
          * Upon receiving an offer, simultaneously start sending UDP packets ("pings") to the peer's specified `NAT_IP:NAT_UDP_Port`.
          * Actively listen on its own STUN-discovered UDP endpoint (via the `P2PUDPProtocol` listening on `INTERNAL_UDP_PORT`) for incoming UDP packets from the peer.
      * Log the success or failure of direct UDP packet exchange.

### Prerequisites

1.  **Completion of Step 3A:** Your Rendezvous Service and Worker Service must be successfully deployed and configured as per your `plann_step3a.md`. This means:
      * Workers are creating UDP sockets (the `udp_socket` global in `holepunch/main.py` is used for STUN).
      * Workers are using STUN (via `pystun3`) to discover their public UDP `NAT_IP:NAT_UDP_Port` (`discovered_udp_ip`, `discovered_udp_port`).
      * Workers are reporting these UDP endpoints to the Rendezvous service via the `update_udp_endpoint` WebSocket message.
      * The Rendezvous service (`rendezvous_service_code/main.py`) stores these UDP endpoints (`stun_reported_udp_ip`, `stun_reported_udp_port`) and they are visible via the `/debug/list_workers` endpoint.
      * The worker service (`holepunch/main.py`) has the placeholder `udp_listener_task`.
2.  **At least two instances** of your Worker Service should be deployable/running.
3.  All previous project setup (`iceberg-eli`, `us-central1` region, networking, Cloud NAT with EIM enabled) remains the same.

-----

## Part 3B.1: Modifications to Rendezvous Service

The Rendezvous service will proactively try to pair workers that have registered UDP endpoints.

### 3B.1.1. Shell Variables (Rendezvous Service)

```bash
export PROJECT_ID="iceberg-eli" # Should be set from gcloud config
export REGION="us-central1"   # Should be set from gcloud config

export AR_RENDEZVOUS_REPO_NAME="rendezvous-repo" # As defined in plann_step3a.md
export RENDEZVOUS_SERVICE_NAME="rendezvous-service" # As defined in plann_step3a.md
export RENDEZVOUS_IMAGE_TAG_V3="v_step3b" # New version tag
```

### 3B.1.2. Rendezvous Service Code (`rendezvous_service_code/main.py`) Updates

The existing `plann_step3a.md` version of `rendezvous_service_code/main.py` already has the correct structure in `connected_workers` to store `stun_reported_udp_ip` and `stun_reported_udp_port`. We'll add the pairing logic.

```python
import asyncio
import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from typing import Dict, Optional, List # Added List
import os
import json

app = FastAPI(title="Rendezvous Service")

# connected_workers structure from your Step 3A implementation:
# { worker_id: { 
#    "public_ip": str, "public_port": int, # From WebSocket connection (or self-reported HTTP IP)
#    "websocket": WebSocket,
#    "udp_ip": Optional[str], "udp_port": Optional[int] # Renamed in debug output, let's align to "stun_reported_udp_ip"
# }}
# Let's ensure keys are consistent:
# "websocket_observed_ip", "websocket_observed_port"
# "http_reported_public_ip" (if you send it)
# "stun_reported_udp_ip", "stun_reported_udp_port"
connected_workers: Dict[str, Dict] = {}

# List of worker_ids that have reported UDP info and are waiting for a peer
workers_ready_for_pairing: List[str] = []

async def attempt_to_pair_workers(newly_ready_worker_id: str):
    global workers_ready_for_pairing, connected_workers

    initiator_data = connected_workers.get(newly_ready_worker_id)
    # Check using the keys from your current plann_step3a.md debug output
    if not initiator_data or not initiator_data.get("stun_reported_udp_ip") or not initiator_data.get("stun_reported_udp_port"):
        print(f"Pairing: Initiator '{newly_ready_worker_id}' does not have STUN UDP info. Cannot pair.")
        if newly_ready_worker_id in workers_ready_for_pairing:
            workers_ready_for_pairing.remove(newly_ready_worker_id)
        return

    # Ensure newly_ready_worker_id is in the list if it's valid and not already being processed
    if newly_ready_worker_id not in workers_ready_for_pairing:
        workers_ready_for_pairing.append(newly_ready_worker_id)
        print(f"Rendezvous: Worker '{newly_ready_worker_id}' added to ready_for_pairing list ({len(workers_ready_for_pairing)} waiting).")

    if len(workers_ready_for_pairing) < 2:
        print(f"Rendezvous: Not enough workers ready for pairing ({len(workers_ready_for_pairing)} waiting).")
        return

    # Take the first two distinct workers from the list
    peer_a_id = workers_ready_for_pairing.pop(0)
    peer_b_id = None
    for potential_peer in workers_ready_for_pairing: # Find a different one
        if potential_peer != peer_a_id:
            peer_b_id = potential_peer
            workers_ready_for_pairing.remove(peer_b_id)
            break
    
    if not peer_b_id: # Could not find a distinct second peer
        workers_ready_for_pairing.insert(0, peer_a_id) # Put peer_a_id back
        print(f"Rendezvous: Could not find a distinct second peer for '{peer_a_id}'. It remains in ready list.")
        return

    peer_a_data = connected_workers.get(peer_a_id)
    peer_b_data = connected_workers.get(peer_b_id)

    # Final check before sending offers
    if not (peer_a_data and peer_b_data and 
            peer_a_data.get("stun_reported_udp_ip") and peer_a_data.get("stun_reported_udp_port") and
            peer_b_data.get("stun_reported_udp_ip") and peer_b_data.get("stun_reported_udp_port")):
        print(f"Pairing Error: Data integrity issue for pairing {peer_a_id} and {peer_b_id}. One might have disconnected or lost UDP info.")
        # Re-add them if they are still valid and individually have UDP info
        if peer_a_data and peer_a_data.get("stun_reported_udp_ip") and peer_a_id not in workers_ready_for_pairing:
            workers_ready_for_pairing.append(peer_a_id)
        if peer_b_data and peer_b_data.get("stun_reported_udp_ip") and peer_b_id not in workers_ready_for_pairing:
            workers_ready_for_pairing.append(peer_b_id)
        return

    peer_a_ws = peer_a_data.get("websocket")
    peer_b_ws = peer_b_data.get("websocket")

    if not (peer_a_ws and hasattr(peer_a_ws, 'client_state') and peer_a_ws.client_state.value == 1 and \
            peer_b_ws and hasattr(peer_b_ws, 'client_state') and peer_b_ws.client_state.value == 1):
        print(f"Pairing Error: WebSocket for {peer_a_id} or {peer_b_id} is not connected.")
        # Re-add to ready list if their data is otherwise fine
        if peer_a_data.get("stun_reported_udp_ip") and peer_a_id not in workers_ready_for_pairing: workers_ready_for_pairing.append(peer_a_id)
        if peer_b_data.get("stun_reported_udp_ip") and peer_b_id not in workers_ready_for_pairing: workers_ready_for_pairing.append(peer_b_id)
        return


    # Offer B's details to A
    offer_to_a_payload = {
        "type": "p2p_connection_offer",
        "peer_worker_id": peer_b_id,
        "peer_udp_ip": peer_b_data["stun_reported_udp_ip"],
        "peer_udp_port": peer_b_data["stun_reported_udp_port"]
    }
    # Offer A's details to B
    offer_to_b_payload = {
        "type": "p2p_connection_offer",
        "peer_worker_id": peer_a_id,
        "peer_udp_ip": peer_a_data["stun_reported_udp_ip"],
        "peer_udp_port": peer_a_data["stun_reported_udp_port"]
    }

    try:
        print(f"Rendezvous: Attempting to pair Worker '{peer_a_id}' with Worker '{peer_b_id}'")
        await peer_a_ws.send_text(json.dumps(offer_to_a_payload))
        print(f"Rendezvous: Sent P2P offer to Worker '{peer_a_id}' (for peer '{peer_b_id}').")
        await peer_b_ws.send_text(json.dumps(offer_to_b_payload))
        print(f"Rendezvous: Sent P2P offer to Worker '{peer_b_id}' (for peer '{peer_a_id}').")
    except Exception as e:
        print(f"Rendezvous: Error sending P2P connection offers: {e}")
        # If sending fails, workers won't be paired. Add them back to the list if they are still valid.
        if peer_a_id not in workers_ready_for_pairing and connected_workers.get(peer_a_id, {}).get("stun_reported_udp_ip"):
            workers_ready_for_pairing.append(peer_a_id)
        if peer_b_id not in workers_ready_for_pairing and connected_workers.get(peer_b_id, {}).get("stun_reported_udp_ip"):
            workers_ready_for_pairing.append(peer_b_id)


@app.websocket("/ws/register/{worker_id}")
async def websocket_register_worker(websocket: WebSocket, worker_id: str):
    global connected_workers, workers_ready_for_pairing
    await websocket.accept()
    # Using keys consistent with plann_step3a.md's Rendezvous main.py for initial registration
    client_host = websocket.client.host 
    client_port = websocket.client.port 
    
    print(f"Worker '{worker_id}' connecting from WebSocket endpoint: {client_host}:{client_port}")

    if worker_id in connected_workers:
        print(f"Worker '{worker_id}' re-connecting or duplicate ID detected.")
        old_ws_data = connected_workers.get(worker_id)
        if old_ws_data:
            old_ws = old_ws_data.get("websocket")
            if old_ws and hasattr(old_ws, 'client_state') and old_ws.client_state.value == 1: # WebSocketState.CONNECTED
                 try:
                    await old_ws.close(code=1000, reason="New connection from same worker ID")
                 except Exception: pass
        if worker_id in workers_ready_for_pairing:
            workers_ready_for_pairing.remove(worker_id)


    connected_workers[worker_id] = {
        "public_ip": client_host, # This is the initially observed IP for the WebSocket
        "public_port": client_port, # This is the initially observed port for the WebSocket
        "websocket": websocket,
        "stun_reported_udp_ip": None, 
        "stun_reported_udp_port": None,
        "http_reported_public_ip": None # For the IP from ipify if used
    }
    print(f"Worker '{worker_id}' registered. WebSocket EP: {client_host}:{client_port}. Total connected: {len(connected_workers)}")

    try:
        while True: 
            raw_data = await websocket.receive_text()
            print(f"Rendezvous: Received raw message from '{worker_id}': {raw_data}")
            try:
                message = json.loads(raw_data)
                msg_type = message.get("type")

                if msg_type == "register_public_ip": # Worker's self-discovered HTTP/general public IP
                    new_ip = message.get("ip")
                    if new_ip and worker_id in connected_workers:
                        connected_workers[worker_id]["http_reported_public_ip"] = new_ip 
                        print(f"Worker '{worker_id}' reported HTTP-based public IP: {new_ip}")
                
                elif msg_type == "update_udp_endpoint": # This is the STUN-discovered UDP IP/Port
                    udp_ip = message.get("udp_ip")
                    udp_port = message.get("udp_port")
                    if udp_ip and udp_port and worker_id in connected_workers:
                        connected_workers[worker_id]["stun_reported_udp_ip"] = udp_ip
                        connected_workers[worker_id]["stun_reported_udp_port"] = int(udp_port)
                        print(f"Worker '{worker_id}' updated STUN UDP endpoint to: {udp_ip}:{udp_port}")
                        await websocket.send_text(json.dumps({"type": "udp_endpoint_ack", "status": "success"}))
                        
                        # Attempt to pair this worker
                        await attempt_to_pair_workers(worker_id)
                    else:
                        await websocket.send_text(json.dumps({"type": "udp_endpoint_ack", "status": "error", "detail": "Missing IP or Port from worker"}))
                
                elif msg_type == "echo_request": # From previous gist if kept
                    payload = message.get("payload", "")
                    await websocket.send_text(json.dumps({
                        "type": "echo_response", 
                        "original_payload": payload, 
                        "processed_by_rendezvous": f"Echo from Rendezvous: {payload.upper()}"
                    }))
                
                elif msg_type == "get_my_details": # From previous gist if kept
                     if worker_id in connected_workers:
                        details = connected_workers[worker_id]
                        await websocket.send_text(json.dumps({
                            "type": "my_details_response", "worker_id": worker_id,
                            "websocket_ip": details.get("public_ip"), "websocket_port": details.get("public_port"),
                            "http_ip": details.get("http_reported_public_ip"),
                            "stun_udp_ip": details.get("stun_reported_udp_ip"), "stun_udp_port": details.get("stun_reported_udp_port"),
                        }))
                else:
                    print(f"Rendezvous: Worker '{worker_id}' sent unhandled message type: {msg_type}")

            except json.JSONDecodeError: print(f"Rendezvous: Worker '{worker_id}' sent non-JSON message: {raw_data}")
            except AttributeError: print(f"Rendezvous: Worker '{worker_id}' sent malformed JSON message: {raw_data}")
            except KeyError: print(f"Rendezvous: Worker '{worker_id}' no longer in connected_workers dict during message processing.")

    except WebSocketDisconnect:
        print(f"Worker '{worker_id}' disconnected from WebSocket EP: {client_host}:{client_port}.")
    except Exception as e:
        print(f"Error with worker '{worker_id}' WebSocket: {type(e).__name__} - {e}")
    finally:
        if worker_id in connected_workers and connected_workers[worker_id].get("websocket") == websocket:
            del connected_workers[worker_id]
            print(f"Worker '{worker_id}' de-registered. Total connected: {len(connected_workers)}")
        if worker_id in workers_ready_for_pairing:
            workers_ready_for_pairing.remove(worker_id)
            print(f"Worker '{worker_id}' removed from ready_for_pairing list due to disconnect/error.")

@app.get("/")
async def read_root():
    return {"message": "Rendezvous Service is running. Check /debug/list_workers"}

@app.get("/debug/list_workers")
async def list_workers():
    # Uses keys consistent with how they are stored in connected_workers
    # and how plann_step3a.md's rendezvous debug output was structured.
    _workers_info = {}
    for _worker_id, _data in list(connected_workers.items()):
        _ws = _data.get("websocket")
        _is_connected = _ws and hasattr(_ws, 'client_state') and _ws.client_state.value == 1
        _workers_info[_worker_id] = {
            "initial_websocket_ip": _data.get("public_ip"), 
            "initial_websocket_port": _data.get("public_port"),
            "http_reported_public_ip": _data.get("http_reported_public_ip"),
            "stun_reported_udp_ip": _data.get("stun_reported_udp_ip"),
            "stun_reported_udp_port": _data.get("stun_reported_udp_port"),
            "websocket_is_connected": _is_connected
        }
    return {"active_websocket_connections": len(connected_workers), "workers_ready_for_pairing_count": len(workers_ready_for_pairing), "workers_details": _workers_info}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=int(os.environ.get("PORT", 8080)))
```

### 3B.1.3. Rendezvous Service `requirements.txt` and `Dockerfile.rendezvous`

No changes needed from Step 3A (which matches your `rendezvous_service_code/requirements.txt` and `Dockerfile.rendezvous` in the `repomix-output.xml`).

### 3B.1.4. Build and Re-deploy the Rendezvous Service

1.  **Build Image:**
    ```bash
    # cd rendezvous_service_code 
    # (Ensure Dockerfile.rendezvous is named Dockerfile, or use -f / --dockerfile)
    gcloud builds submit --region=$REGION \
        --tag ${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_RENDEZVOUS_REPO_NAME}/${RENDEZVOUS_SERVICE_NAME}:${RENDEZVOUS_IMAGE_TAG_V3} . \
        --dockerfile=Dockerfile.rendezvous
    ```
2.  **Re-deploy Rendezvous Service:**
    ```bash
    gcloud run deploy $RENDEZVOUS_SERVICE_NAME \
        --project=$PROJECT_ID \
        --image=${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_RENDEZVOUS_REPO_NAME}/${RENDEZVOUS_SERVICE_NAME}:${RENDEZVOUS_IMAGE_TAG_V3} \
        --platform=managed --region=$REGION --allow-unauthenticated --session-affinity \
        --min-instances=1 
    ```

-----

## Part 3B.2: Modifications to Worker Service

The Worker (`holepunch/main.py` in your `repomix-output.xml`) needs to:

  * Properly initialize and use an asyncio-compatible UDP listener (`P2PUDPProtocol`).
  * Handle the incoming `p2p_connection_offer` from the Rendezvous service.
  * Implement the `attempt_udp_hole_punch` function to send UDP pings.

### 3B.2.1. Shell Variables (Worker Service)

```bash
export PROJECT_ID="iceberg-eli" # Should be set
export REGION="us-central1"   # Should be set

export AR_WORKER_REPO_NAME="ip-worker-repo" # From your plann_step3a.md
export WORKER_SERVICE_NAME="ip-worker-service" # From your plann_step3a.md
export WORKER_IMAGE_TAG_V4="v_step3b" # New version tag

# RENDEZVOUS_SERVICE_URL, STUN_HOST, STUN_PORT should be set from Step 3A
# export RENDEZVOUS_SERVICE_URL="https://rendezvous-service-xxxx-uc.a.run.app" 
export INTERNAL_UDP_PORT_ENV_VAR_VALUE="8081" # Define the internal port worker listens on
```

### 3B.2.2. Worker Service Code (`holepunch/main.py`) Updates

This integrates the `P2PUDPProtocol` and the hole-punching logic.

```python
import asyncio
import os
import uuid
import websockets
import signal
import threading
import http.server
import socketserver
import requests # Still used for ipify
import json
import socket
import stun # pystun3
from typing import Optional, Tuple

# --- Global Variables (matching your existing holepunch/main.py structure) ---
worker_id = str(uuid.uuid4())
stop_signal_received = False
# udp_socket was used for STUN in 3A, let's rename for clarity or manage scope
# For P2P, the listener will have its own transport, and sending might use that or a new socket.
# Let's manage one main UDP socket/transport for P2P listening and sending.
p2p_udp_transport: Optional[asyncio.DatagramTransport] = None
# STUN discovered external endpoint for *our* UDP listener
our_stun_discovered_udp_ip: Optional[str] = None
our_stun_discovered_udp_port: Optional[int] = None

DEFAULT_STUN_HOST = "stun.l.google.com" # As in your plann_step3a.md
DEFAULT_STUN_PORT = 19302             # As in your plann_step3a.md
INTERNAL_UDP_PORT = int(os.environ.get("INTERNAL_UDP_PORT", "8081")) # Port our UDP listener binds to

# --- Signal Handler (minor update to include p2p_udp_transport) ---
def handle_shutdown_signal(signum, frame):
    global stop_signal_received, p2p_udp_transport
    print(f"Shutdown signal ({signum}) received. Worker '{worker_id}' attempting graceful shutdown.")
    stop_signal_received = True
    if p2p_udp_transport:
        try:
            p2p_udp_transport.close()
            print(f"Worker '{worker_id}': P2P UDP transport closed.")
        except Exception as e:
            print(f"Worker '{worker_id}': Error closing P2P UDP transport: {e}")

# --- Asyncio Datagram Protocol for P2P UDP Listener (from previous Step 3B plan) ---
class P2PUDPProtocol(asyncio.DatagramProtocol):
    def __init__(self, worker_id_val: str):
        self.worker_id = worker_id_val
        self.transport: Optional[asyncio.DatagramTransport] = None
        print(f"Worker '{self.worker_id}': P2PUDPProtocol instance created.")

    def connection_made(self, transport: asyncio.DatagramTransport):
        global p2p_udp_transport # Store the transport globally for sending
        self.transport = transport
        p2p_udp_transport = transport 
        local_addr = transport.get_extra_info('sockname')
        print(f"Worker '{self.worker_id}': P2P UDP listener active on {local_addr} (Internal Port: {INTERNAL_UDP_PORT}). Ready for P2P UDP packets.")

    def datagram_received(self, data: bytes, addr: Tuple[str, int]):
        message = data.decode(errors='ignore')
        print(f"Worker '{self.worker_id}': == UDP Packet Received from {addr}: '{message}' ==")
        # Simple PING/PONG logic
        if message.startswith("P2P_PING_FROM_"):
            peer_id_part = message.split("P2P_PING_FROM_")[1].split("_NUM_")[0]
            print(f"Worker '{self.worker_id}': !!! P2P UDP Ping received from peer (likely {peer_id_part} via {addr}) !!!")
            try:
                response_message = f"P2P_PONG_FROM_{self.worker_id}_TO_{peer_id_part}".encode()
                self.transport.sendto(response_message, addr) # Send PONG back to the sender's address
                print(f"Worker '{self.worker_id}': Sent UDP PONG to {addr}")
            except Exception as e:
                print(f"Worker '{self.worker_id}': Error sending UDP PONG: {e}")
        elif message.startswith("P2P_PONG_FROM_"):
            print(f"Worker '{self.worker_id}': !!! P2P UDP Pong received from {addr} !!!")

    def error_received(self, exc: Exception):
        print(f"Worker '{self.worker_id}': P2P UDP listener error: {exc}")

    def connection_lost(self, exc: Optional[Exception]):
        global p2p_udp_transport
        print(f"Worker '{self.worker_id}': P2P UDP listener connection lost: {exc if exc else 'Closed normally'}")
        if self.transport == p2p_udp_transport:
            p2p_udp_transport = None # Clear global ref

# --- STUN Discovery (adapting your existing `discover_udp_endpoint_and_report` from plann_step3a.md/repomix) ---
async def discover_and_report_stun_udp_endpoint(websocket_conn):
    global our_stun_discovered_udp_ip, our_stun_discovered_udp_port, worker_id
    
    # For STUN discovery, we need a socket bound to *some* local port.
    # pystun3's get_ip_info can take source_ip and source_port for the local socket.
    # If source_port is 0, it binds to an ephemeral port.
    # This discovered external mapping is what we report.
    # Our actual P2P listener will be on INTERNAL_UDP_PORT.
    
    temp_stun_socket_for_discovery = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        temp_stun_socket_for_discovery.bind(("0.0.0.0", 0)) # Bind to an ephemeral local port for STUN query
        local_stun_query_port = temp_stun_socket_for_discovery.getsockname()[1]

        stun_host = os.environ.get("STUN_HOST", DEFAULT_STUN_HOST)
        stun_port = int(os.environ.get("STUN_PORT", DEFAULT_STUN_PORT))
        
        print(f"Worker '{worker_id}': Attempting STUN discovery via {stun_host}:{stun_port} using temp local UDP port {local_stun_query_port}.")
        
        # pystun3.get_ip_info creates its own socket internally for the query if source_ip/port are not the actual socket.
        # Or, it can use the one provided by source_port if you pass the socket itself via `sock` (not standard in pystun3 CLI version).
        # The `source_port` parameter to `stun.get_ip_info` tells it which local port to use for the STUN binding request.
        nat_type, external_ip, external_port = stun.get_ip_info(
            source_ip="0.0.0.0", # Tells pystun3 to pick an interface
            source_port=local_stun_query_port, # The local port from which the STUN request will be sent
            stun_host=stun_host, 
            stun_port=stun_port
        )
        print(f"Worker '{worker_id}': STUN discovery result: NAT Type='{nat_type}', External IP='{external_ip}', External Port={external_port}")

        if external_ip and external_port:
            our_stun_discovered_udp_ip = external_ip
            our_stun_discovered_udp_port = external_port
            
            await websocket_conn.send(json.dumps({
                "type": "update_udp_endpoint", # Message type Rendezvous expects
                "udp_ip": our_stun_discovered_udp_ip,
                "udp_port": our_stun_discovered_udp_port
            }))
            print(f"Worker '{worker_id}': Sent STUN-discovered UDP endpoint ({our_stun_discovered_udp_ip}:{our_stun_discovered_udp_port}) to Rendezvous.")
            return True
        else:
            print(f"Worker '{worker_id}': STUN discovery failed to return valid external IP/Port.")
            return False
    except stun.StunError as e: # Catch specific pystun3 error
        print(f"Worker '{worker_id}': STUN error during discovery: {e}")
        return False
    except socket.gaierror as e: 
        print(f"Worker '{worker_id}': STUN host DNS resolution error: {e}")
        return False
    except Exception as e:
        print(f"Worker '{worker_id}': General error during STUN discovery: {type(e).__name__} - {e}")
        return False
    finally:
        if temp_stun_socket_for_discovery:
            temp_stun_socket_for_discovery.close()
            print(f"Worker '{worker_id}': Temp STUN UDP socket closed.")

# --- UDP Hole Punching Logic ---
async def start_udp_hole_punch(peer_udp_ip: str, peer_udp_port: int, peer_worker_id: str):
    global worker_id, stop_signal_received, p2p_udp_transport, our_stun_discovered_udp_ip, INTERNAL_UDP_PORT
    
    if not p2p_udp_transport: # Check if our main UDP listener's transport is active
        print(f"Worker '{worker_id}': P2P UDP listener transport not available. Cannot effectively send P2P pings.")
        return

    print(f"Worker '{worker_id}': Starting UDP hole punch sequence towards peer '{peer_worker_id}' at {peer_udp_ip}:{peer_udp_port}")
    print(f"Worker '{worker_id}': My STUN-discovered public UDP endpoint is {our_stun_discovered_udp_ip}:{our_stun_discovered_udp_port}")
    print(f"Worker '{worker_id}': My internal P2P UDP listener is on port {INTERNAL_UDP_PORT}")

    target_addr = (peer_udp_ip, peer_udp_port)

    # Send a burst of packets to try and establish the NAT mapping ("punch the hole")
    # The listener (P2PUDPProtocol) is already active and should receive replies or pings from the peer.
    for i in range(1, 6): # Send 5 pings
        if stop_signal_received: break
        try:
            message_content = f"P2P_PING_FROM_{worker_id}_NUM_{i}"
            message_bytes = message_content.encode()
            
            p2p_udp_transport.sendto(message_bytes, target_addr) # Use the listener's transport to send

            print(f"Worker '{worker_id}': Sent UDP PING {i} ('{message_content}') to {target_addr} via listener transport.")
        except Exception as e:
            print(f"Worker '{worker_id}': Error sending UDP PING {i}: {e}")
        await asyncio.sleep(0.75) # Stagger pings a bit
    
    print(f"Worker '{worker_id}': Finished UDP PING burst for hole punching to '{peer_worker_id}'. Now relying on listener.")

# --- Main WebSocket Connection Logic (adapting your existing connect_to_rendezvous) ---
async def connect_to_rendezvous(rendezvous_ws_url: str):
    global stop_signal_received, our_stun_discovered_udp_ip, our_stun_discovered_udp_port, p2p_udp_transport, INTERNAL_UDP_PORT
    
    # Existing ip_echo_service_url and ping settings from your current main.py
    ip_echo_service_url = "https://api.ipify.org"
    ping_interval = float(os.environ.get("PING_INTERVAL_SEC", "25"))
    ping_timeout = float(os.environ.get("PING_TIMEOUT_SEC", "25"))
    
    # Ensure any previous UDP transport is cleared before a new connection attempt
    if p2p_udp_transport:
        p2p_udp_transport.close()
        p2p_udp_transport = None

    while not stop_signal_received:
        current_udp_listener_task = None
        try:
            async with websockets.connect(
                rendezvous_ws_url,
                ping_interval=ping_interval,
                ping_timeout=ping_timeout,
            ) as websocket:
                print(f"Worker '{worker_id}' connected to Rendezvous via WebSocket.")

                # 1. Report HTTP-based public IP (optional, as in your current code)
                try:
                    # ... (Your existing requests.get(ip_echo_service_url) logic) ...
                    response = requests.get(ip_echo_service_url, timeout=10)
                    response.raise_for_status()
                    http_public_ip = response.text.strip()
                    await websocket.send(json.dumps({"type": "register_public_ip", "ip": http_public_ip}))
                    print(f"Worker '{worker_id}' sent HTTP-based public IP ({http_public_ip}) to Rendezvous.")
                except Exception as e:
                    print(f"Worker '{worker_id}': Error fetching/sending HTTP-based public IP: {e}.")

                # 2. Discover and report STUN UDP endpoint
                stun_success = await discover_and_report_stun_udp_endpoint(websocket)

                # 3. If STUN was successful, start the asyncio UDP listener on INTERNAL_UDP_PORT
                if stun_success and not p2p_udp_transport: # Start listener only if STUN worked and not already running
                    try:
                        loop = asyncio.get_running_loop()
                        # The transport is stored in p2p_udp_transport by P2PUDPProtocol.connection_made
                        _transport, _protocol = await loop.create_datagram_endpoint(
                            lambda: P2PUDPProtocol(worker_id),
                            local_addr=('0.0.0.0', INTERNAL_UDP_PORT) 
                        )
                        # Give a moment for connection_made to set p2p_udp_transport
                        await asyncio.sleep(0.1) 
                        if p2p_udp_transport:
                             print(f"Worker '{worker_id}': Asyncio P2P UDP listener started on 0.0.0.0:{INTERNAL_UDP_PORT}.")
                        else:
                             print(f"Worker '{worker_id}': Asyncio P2P UDP listener transport NOT SET after create_datagram_endpoint.")
                    except Exception as e:
                        print(f"Worker '{worker_id}': Failed to start asyncio P2P UDP listener on port {INTERNAL_UDP_PORT}: {type(e).__name__} - {e}")
                
                # Main WebSocket receive loop
                while not stop_signal_received:
                    try:
                        message_raw = await asyncio.wait_for(websocket.recv(), timeout=max(30.0, ping_interval + ping_timeout + 10))
                        print(f"Worker '{worker_id}': RAW Received from Rendezvous (WebSocket): {message_raw}")
                        try:
                            message_data = json.loads(message_raw)
                            msg_type = message_data.get("type")
                            
                            if msg_type == "udp_endpoint_ack":
                                print(f"Worker '{worker_id}': Received UDP endpoint ack from Rendezvous: {message_data.get('status')}")
                            elif msg_type == "echo_response": # From your previous gists
                                print(f"Worker '{worker_id}': Echo Response from Rendezvous: {message_data.get('processed_by_rendezvous')}")
                            elif msg_type == "my_details_response": # From your previous gists
                                print(f"Worker '{worker_id}': My Details from Rendezvous: IP={message_data.get('stun_udp_ip')}, Port={message_data.get('stun_udp_port')}")
                            
                            # NEW: Handle P2P connection offer from Rendezvous
                            elif msg_type == "p2p_connection_offer":
                                peer_id = message_data.get("peer_worker_id")
                                peer_ip = message_data.get("peer_udp_ip") # This is STUN-discovered external IP of peer
                                peer_port = message_data.get("peer_udp_port") # STUN-discovered external Port of peer
                                
                                if peer_id and peer_ip and peer_port:
                                    print(f"Worker '{worker_id}': Received P2P connection offer for peer '{peer_id}' at UDP endpoint {peer_ip}:{peer_port}")
                                    if p2p_udp_transport and our_stun_discovered_udp_ip: # Ensure our UDP setup is ready
                                        print(f"Worker '{worker_id}': My UDP Listener active & STUN info present. Starting hole punch task.")
                                        asyncio.create_task(start_udp_hole_punch(peer_ip, int(peer_port), peer_id))
                                    else:
                                        print(f"Worker '{worker_id}': Cannot initiate P2P: My UDP listener not active or STUN discovery incomplete.")
                                else:
                                    print(f"Worker '{worker_id}': Received incomplete P2P connection offer: {message_data}")
                            else:
                                print(f"Worker '{worker_id}': Received unhandled message type '{msg_type}' from Rendezvous.")
                        except json.JSONDecodeError:
                            print(f"Worker '{worker_id}': Received non-JSON message from Rendezvous: {message_raw}")
                    except asyncio.TimeoutError:
                        pass # Normal due to recv timeout, pings handle keepalive
                    except websockets.exceptions.ConnectionClosed:
                        print(f"Worker '{worker_id}': Rendezvous WebSocket connection closed by server during recv loop.")
                        break 
                
        except websockets.exceptions.ConnectionClosedOK:
            print(f"Worker '{worker_id}': Rendezvous WebSocket connection closed gracefully by server.")
        except websockets.exceptions.InvalidURI:
            print(f"Worker '{worker_id}': Invalid Rendezvous WebSocket URI: {rendezvous_ws_url}. Exiting.")
            if p2p_udp_transport: p2p_udp_transport.close(); p2p_udp_transport = None # Clean up transport
            return 
        except ConnectionRefusedError:
            print(f"Worker '{worker_id}': Connection to Rendezvous refused. Retrying in 10 seconds...")
        except Exception as e: 
            print(f"Worker '{worker_id}': Error in WebSocket connect_to_rendezvous outer loop: {type(e).__name__} - {e}. Retrying in 10s...")
        
        finally: # Cleanup for this specific WebSocket connection attempt
            if p2p_udp_transport:
                print(f"Worker '{worker_id}': Closing P2P UDP transport in connect_to_rendezvous finally block (after WebSocket attempt).")
                p2p_udp_transport.close()
                p2p_udp_transport = None
        
        if not stop_signal_received:
            await asyncio.sleep(10) 
        else:
            break 

    print(f"Worker '{worker_id}' has stopped WebSocket connection attempts.")

# --- Health Check Server (unchanged from your current main.py) ---
def start_healthcheck_http_server():
    class _Handler(http.server.BaseHTTPRequestHandler):
        def do_GET(self): self.send_response(200); self.send_header("Content-Type","text/plain"); self.end_headers(); self.wfile.write(b"OK")
        def log_message(self, format, *args): return
    port = int(os.environ.get("PORT", 8080))
    httpd = socketserver.TCPServer(("0.0.0.0", port), _Handler)
    threading.Thread(target=httpd.serve_forever, daemon=True).start()
    print(f"Health-check HTTP server listening on 0.0.0.0:{port}")

start_healthcheck_http_server() # This is already in your main.py

# --- __main__ block (adapting your existing main.py __main__) ---
if __name__ == "__main__":
    print(f"WORKER SCRIPT (ID: {worker_id}): Starting main process.")
    
    rendezvous_base_url_env = os.environ.get("RENDEZVOUS_SERVICE_URL")
    if not rendezvous_base_url_env:
        print("CRITICAL ERROR: RENDEZVOUS_SERVICE_URL environment variable not set. Exiting worker.")
        exit(1)

    # Construct WebSocket URL (consistent with your main.py)
    if rendezvous_base_url_env.startswith("http://"):
        ws_url_constructed = rendezvous_base_url_env.replace("http://", "ws://", 1)
    elif rendezvous_base_url_env.startswith("https://"):
        ws_url_constructed = rendezvous_base_url_env.replace("https://", "wss://", 1)
    else: # Assuming a raw domain:port that might be for local testing
        print(f"Warning: Rendezvous URL '{rendezvous_base_url_env}' lacks http/https scheme. Prepending 'ws://' as a default guess for local or non-SSL.")
        ws_url_constructed = "ws://" + rendezvous_base_url_env 
    full_rendezvous_ws_url = f"{ws_url_constructed}/ws/register/{worker_id}"
    
    print(f"Worker '{worker_id}': Configured to connect to Rendezvous at: {full_rendezvous_ws_url}")
    
    signal.signal(signal.SIGTERM, handle_shutdown_signal)
    signal.signal(signal.SIGINT, handle_shutdown_signal)

    try:
        asyncio.run(connect_to_rendezvous(full_rendezvous_ws_url))
    except KeyboardInterrupt:
        print(f"Worker '{worker_id}' interrupted by user (KeyboardInterrupt).")
        stop_signal_received = True # Ensure loops terminate
    except Exception as e_main:
        print(f"Worker '{worker_id}' CRITICAL ERROR in main asyncio.run: {type(e_main).__name__} - {e_main}")
    finally:
        print(f"Worker '{worker_id}' main process exiting. stop_signal_received={stop_signal_received}")
        # Final cleanup of the UDP transport if it was somehow left open
        if p2p_udp_transport and not p2p_udp_transport.is_closing():
            print(f"Worker '{worker_id}': Performing final close of P2P UDP transport in __main__ finally.")
            p2p_udp_transport.close()
```

### 3B.2.3. Worker Service `requirements.txt` (`holepunch/requirements.txt`)

This remains the same as your `plann_step3a.md` and current `requirements.txt`:

```
websockets>=12.0
requests>=2.0.0 
pystun3>=1.1.6 
```

### 3B.2.4. Worker Service `Dockerfile.worker` (`holepunch/Dockerfile.worker`)

No changes needed from your current `Dockerfile.worker` (which should have `CMD ["python", "-u", "main.py"]`).

### 3B.2.5. Build and Re-deploy the Worker Service

1.  **Build Image (from `holepunch` directory):**
    *(Use your existing build commands from `plann_step3a.md`, just update the image tag)*
    ```bash
    # cd path/to/holepunch
    # (Ensure Dockerfile.worker is named Dockerfile or use -f with docker build/buildx or --dockerfile with gcloud)
    gcloud builds submit --region=$REGION \
        --tag ${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_WORKER_REPO_NAME}/${WORKER_SERVICE_NAME}:${WORKER_IMAGE_TAG_V4} . \
        --dockerfile=Dockerfile.worker 
    ```
2.  **Re-deploy Worker Service (MINIMUM 2 INSTANCES):**
    ```bash
    gcloud run deploy $WORKER_SERVICE_NAME \
        --project=$PROJECT_ID \
        --image=${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_WORKER_REPO_NAME}/${WORKER_SERVICE_NAME}:${WORKER_IMAGE_TAG_V4} \
        --platform=managed \
        --region=$REGION \
        --update-env-vars="RENDEZVOUS_SERVICE_URL=${RENDEZVOUS_SERVICE_URL},STUN_HOST=${STUN_HOST:-stun.l.google.com},STUN_PORT=${STUN_PORT:-19302},INTERNAL_UDP_PORT=${INTERNAL_UDP_PORT_ENV_VAR_VALUE}" \
        --vpc-egress=all-traffic \
        --network=ip-worker-vpc \
        --subnet=ip-worker-subnet \
        --min-instances=2 \
        --max-instances=2 \
        --cpu-boost # Consider enabling CPU boost for potentially faster network I/O and task scheduling
        # --concurrency=10 # Default is 80. For primarily network I/O bound tasks like this, higher might be okay,
                           # but for 2 instances and simple PING/PONG, default is likely fine.
    ```
      * Added `INTERNAL_UDP_PORT` environment variable. Set to `8081` by the shell variable.
      * Set `--min-instances=2` and `--max-instances=2` to ensure you have two workers for P2P.
      * `--cpu-boost` can help with the responsiveness needed for hole punching.

-----

## Part 3B.3: Verification

1.  **Deploy/Update both services:** Rendezvous (`v_step3b` tag) first, then ensure at least two instances of Worker (`v_step3b` tag for worker, or `WORKER_IMAGE_TAG_V4`) are running.
2.  **Monitor Rendezvous Service Logs:**
      * Confirm both workers connect and register their STUN-discovered UDP endpoints.
      * Look for logs indicating it's pairing workers and sending `p2p_connection_offer` messages to both.
3.  **Monitor Worker A's Logs & Worker B's Logs:**
      * STUN success, UDP listener started on internal port (e.g., 8081).
      * WebSocket connection and UDP endpoint registration acknowledged by Rendezvous.
      * Receiving `p2p_connection_offer` for its peer from Rendezvous.
      * Logs from `attempt_udp_hole_punch`: `Sent UDP PING X to Peer_NAT_IP:Peer_NAT_Port`.
      * **CRUCIAL SUCCESS LOG (on both workers, for packets from the other):**
        `Worker '...' == UDP Packet Received from Peer_NAT_IP:Peer_NAT_Source_Port: 'P2P_PING_FROM_peer-id_NUM_Y'`
        `Worker '...' !!! P2P UDP Ping received from peer ... !!!`
        `Worker '...' Sent UDP PONG to Peer_NAT_IP:Peer_NAT_Source_Port`
        And subsequently:
        `Worker '...' == UDP Packet Received from Peer_NAT_IP:Peer_NAT_Source_Port: 'P2P_PONG_FROM_peer-id_TO_own-id'`
        `Worker '...' !!! P2P UDP Pong received from Peer_NAT_IP:Peer_NAT_Source_Port !!!`

**What "Success" for Step 3B Looks Like:**
If both Worker A and Worker B log that they have *received UDP PINGs and PONGs directly from each other's public NAT IP addresses*, then UDP hole punching has been successful\!

This refined plan for Step 3B should align well with your existing codebase from Step 3A and guide you through implementing and verifying direct P2P UDP communication.
</file>

<file path="plann_step4a">
That's fantastic news\! Seeing those "P2P\_PING" and "P2P\_PONG" messages flowing directly between your Cloud Run workers via UDP is a huge success and confirms that the core UDP hole punching mechanism is working. Congratulations on this significant milestone\!

Now, let's make this interactive and visible in a browser, as you requested. This will be **Step 4: Real-time P2P Data Exchange with Web UI**. We'll break this into a couple of parts as well.

**Step 4 - Part A: Worker Web UI, Local WebSocket Server, and P2P Data Send**

**Objective:**

1.  Modify the **Worker Service** (`holepunch/main.py`) to:
      * Serve a simple HTML page (`index.html`) that will act as the user interface.
      * Run a WebSocket server that this local `index.html` can connect to.
      * When a user types a message into the `index.html` UI and sends it:
          * The message is sent from the browser JavaScript to the worker's Python backend via this new *local* WebSocket.
          * The Python backend then takes this message and sends it over the established P2P UDP connection to its peer worker.
2.  The peer worker (receiving the UDP message) will initially just log it (we'll make it display in its UI in Step 4B).
3.  The `index.html` will have an input field to send messages and an area to display received messages (though receiving display will be fully implemented in 4B).

This step focuses on getting data *from* a browser UI on one worker, through its Python backend, over P2P UDP, to the *Python backend* of the peer worker.

-----

## README - Step 4 (Part A): Worker Web UI, Local WebSocket, and P2P UDP Send

### Prerequisites

1.  **Completion of Step 3B:** Your Rendezvous Service and Worker Services are successfully deployed. UDP hole punching is working, and you can see PING/PONG messages exchanged directly between worker instances in the logs.
2.  All previous project setup (`iceberg-eli`, `us-central1` region, networking, Cloud NAT, etc.) remains the same.
3.  At least two instances of your Worker Service should be deployable.

-----

## Part 4A.1: Modifications to Worker Service (`holepunch/`)

The `holepunch/main.py` will undergo significant changes to incorporate an HTTP server for the HTML page and a WebSocket server for communication with that page, all while maintaining its existing roles (Rendezvous client, STUN client, P2P UDP agent).

### 4A.1.1. Shell Variables (Worker Service)

```bash
export PROJECT_ID="iceberg-eli" 
export REGION="us-central1"   

export AR_WORKER_REPO_NAME="ip-worker-repo" 
export WORKER_SERVICE_NAME="ip-worker-service" 
export WORKER_IMAGE_TAG_V5="v_step4a" # New version tag

# RENDEZVOUS_SERVICE_URL, STUN_HOST, STUN_PORT, INTERNAL_UDP_PORT should be set from Step 3
# Example: export RENDEZVOUS_SERVICE_URL="https://rendezvous-service-xxxx-uc.a.run.app"
# Example: export INTERNAL_UDP_PORT="8081"
```

### 4A.1.2. Create `holepunch/index.html` (NEW FILE)

Create this new file in your `holepunch` directory.

```html
<!DOCTYPE html>
<html>
<head>
    <title>P2P UDP Chat - Worker: <span id="workerIdSpan"></span></title>
    <style>
        body { font-family: sans-serif; margin: 10px; background-color: #f4f4f4; }
        #chatbox { width: 95%; height: 300px; border: 1px solid #ccc; overflow-y: scroll; padding: 10px; background-color: #fff; margin-bottom: 10px; }
        #messageInput { width: 80%; padding: 10px; margin-right: 5px; border: 1px solid #ccc; }
        #sendButton { padding: 10px; background-color: #5cb85c; color: white; border: none; cursor: pointer; }
        #sendButton:hover { background-color: #4cae4c; }
        .message { margin-bottom: 5px; padding: 5px; border-radius: 3px; }
        .local { background-color: #d1e7dd; text-align: right; margin-left: 20%; }
        .peer { background-color: #f8d7da; text-align: left; margin-right: 20%;}
        .system { background-color: #e2e3e5; color: #555; font-style: italic; font-size: 0.9em;}
        #status { margin-top: 10px; font-size: 0.9em; color: #777; }
        #peerInfo { margin-top: 5px; font-size: 0.9em; color: #337ab7; }
    </style>
</head>
<body>
    <h1>P2P UDP Chat - Worker: <span id="workerIdSpan"></span></h1>
    <div id="status">Connecting to local worker backend...</div>
    <div id="peerInfo">Peer: Not connected</div>
    <div id="chatbox"></div>
    <input type="text" id="messageInput" placeholder="Type message..."/>
    <button id="sendButton">Send</button>

    <script>
        const workerIdSpan = document.getElementById('workerIdSpan');
        const chatbox = document.getElementById('chatbox');
        const messageInput = document.getElementById('messageInput');
        const sendButton = document.getElementById('sendButton');
        const statusDiv = document.getElementById('status');
        const peerInfoDiv = document.getElementById('peerInfo');

        let localUiSocket = null;
        let myWorkerId = "Unknown"; // Will be updated by backend

        function addMessage(text, type = "system", sender = "") {
            const messageDiv = document.createElement('div');
            messageDiv.classList.add('message', type);
            if (type === 'local' || type === 'peer') {
                 messageDiv.textContent = `${sender}: ${text}`;
            } else {
                 messageDiv.textContent = text;
            }
            chatbox.appendChild(messageDiv);
            chatbox.scrollTop = chatbox.scrollHeight; // Auto-scroll
        }

        function connectToLocalBackend() {
            // The WebSocket server will run on the same host, different port, or same port with specific path.
            // For Cloud Run, it's simpler if it's the same port but a different path.
            // If serving HTTP and WS on same port with `websockets` library, need careful path handling.
            // Let's assume for now worker backend exposes WS on /ui-ws on its main PORT (e.g., 8080)
            const wsProtocol = window.location.protocol === "https:" ? "wss:" : "ws:";
            const localWsUrl = `${wsProtocol}//${window.location.host}/ui_ws`; 
            
            addMessage(`Attempting to connect to local UI WebSocket at ${localWsUrl}`, "system");
            localUiSocket = new WebSocket(localWsUrl);

            localUiSocket.onopen = function(event) {
                statusDiv.textContent = "Connected to local worker backend. Waiting for P2P link...";
                addMessage("Connection to local worker backend established.", "system");
                // Request worker ID or other initial info
                localUiSocket.send(JSON.stringify({type: "ui_client_hello"}));
            };

            localUiSocket.onmessage = function(event) {
                try {
                    const data = JSON.parse(event.data);
                    console.log("Message from local worker backend:", data);
                    if (data.type === "init_info") {
                        myWorkerId = data.worker_id;
                        workerIdSpan.textContent = myWorkerId.substring(0,8) + "...";
                        addMessage(`Worker ID: ${myWorkerId}`, "system");
                         if(data.p2p_peer_id) {
                            peerInfoDiv.textContent = `P2P Connected to Peer: ${data.p2p_peer_id.substring(0,8)}...`;
                            statusDiv.textContent = "P2P Link Active.";
                        }
                    } else if (data.type === "p2p_message_received") {
                        addMessage(data.content, "peer", data.from_peer_id ? data.from_peer_id.substring(0,8)+"..." : "Peer");
                    } else if (data.type === "p2p_status_update") {
                        addMessage(`P2P Status: ${data.message}`, "system");
                        if (data.peer_id) {
                            peerInfoDiv.textContent = `P2P Connected to Peer: ${data.peer_id.substring(0,8)}...`;
                            statusDiv.textContent = "P2P Link Active.";
                        } else {
                             peerInfoDiv.textContent = "Peer: Not connected";
                             if (!data.message.toLowerCase().includes("lost")) {
                                statusDiv.textContent = "P2P Link Inactive.";
                             }
                        }
                    } else if (data.type === "error") {
                        addMessage(`Error from backend: ${data.message}`, "system");
                    }
                } catch (e) {
                    addMessage("Received non-JSON message from backend: " + event.data, "system");
                }
            };

            localUiSocket.onclose = function(event) {
                statusDiv.textContent = "Disconnected from local worker backend. Attempting to reconnect...";
                addMessage("Connection to local worker backend closed. Retrying in 5s...", "system");
                setTimeout(connectToLocalBackend, 5000);
            };

            localUiSocket.onerror = function(error) {
                statusDiv.textContent = "Error connecting to local worker backend.";
                addMessage("WebSocket error with local worker backend: " + error.message, "system");
                console.error("WebSocket Error: ", error);
            };
        }

        sendButton.onclick = function() {
            const messageText = messageInput.value;
            if (messageText && localUiSocket && localUiSocket.readyState === WebSocket.OPEN) {
                localUiSocket.send(JSON.stringify({
                    type: "send_p2p_message",
                    content: messageText
                }));
                addMessage(messageText, "local", "Me (" + (myWorkerId ? myWorkerId.substring(0,8)+"..." : "") + ")");
                messageInput.value = '';
            } else {
                addMessage("Cannot send message. Not connected to local backend or message is empty.", "system");
            }
        };
        
        messageInput.addEventListener("keypress", function(event) {
            if (event.key === "Enter") {
                event.preventDefault();
                sendButton.click();
            }
        });

        // Initial connection attempt
        connectToLocalBackend();
    </script>
</body>
</html>
```

### 4A.1.3. Worker Service Code (`holepunch/main.py`) Updates

This is the most significant part. We need to add an HTTP server to serve `index.html` and a WebSocket server for the UI, and integrate them with the existing `asyncio` loop and P2P logic.

```python
import asyncio
import os
import uuid
import websockets # For Rendezvous client AND UI server
import signal
import threading
import http.server 
import socketserver 
import requests 
import json
import socket
import stun # pystun3
from typing import Optional, Tuple, Set # Added Set for UI clients

from pathlib import Path # For serving HTML file

# --- Global Variables ---
worker_id = str(uuid.uuid4())
stop_signal_received = False
p2p_udp_transport: Optional[asyncio.DatagramTransport] = None
our_stun_discovered_udp_ip: Optional[str] = None
our_stun_discovered_udp_port: Optional[int] = None
current_p2p_peer_id: Optional[str] = None # To know who we are talking to via UDP
current_p2p_peer_addr: Optional[Tuple[str, int]] = None # (ip, port) for current UDP peer

DEFAULT_STUN_HOST = os.environ.get("STUN_HOST", "stun.l.google.com")
DEFAULT_STUN_PORT = int(os.environ.get("STUN_PORT", "19302"))
INTERNAL_UDP_PORT = int(os.environ.get("INTERNAL_UDP_PORT", "8081"))
HTTP_PORT_FOR_UI = int(os.environ.get("PORT", 8080)) # Cloud Run provides PORT

# For UI WebSocket server
ui_websocket_clients: Set[websockets.WebSocketServerProtocol] = set()

# --- Signal Handler (no major changes from Step 3B) ---
def handle_shutdown_signal(signum, frame):
    global stop_signal_received, p2p_udp_transport
    print(f"Shutdown signal ({signum}) received. Worker '{worker_id}' attempting graceful shutdown.")
    stop_signal_received = True
    if p2p_udp_transport:
        try: p2p_udp_transport.close(); print(f"Worker '{worker_id}': P2P UDP transport closed.")
        except Exception as e: print(f"Worker '{worker_id}': Error closing P2P UDP transport: {e}")
    # Also try to close UI WebSockets gracefully
    for ws_client in list(ui_websocket_clients):
        asyncio.create_task(ws_client.close(reason="Server shutting down"))


# --- HTTP Server for index.html (Async) ---
async def serve_index_html(reader: asyncio.StreamReader, writer: asyncio.StreamWriter):
    try:
        # Basic HTTP request parsing (enough for GET /)
        request_line = await reader.readline()
        if not request_line: # Connection closed by client
             writer.close()
             await writer.wait_closed()
             return

        header = request_line.decode().strip()
        # print(f"HTTP Request: {header}") # Debug

        # Read headers
        while True:
            line = await reader.readline()
            if not line.strip(): # End of headers
                break
        
        if header.startswith("GET / "):
            try:
                html_path = Path(__file__).parent / "index.html"
                with open(html_path, "r") as f:
                    content = f.read()
                response = f"HTTP/1.1 200 OK\r\nContent-Type: text/html\r\nContent-Length: {len(content)}\r\nConnection: close\r\n\r\n{content}"
            except FileNotFoundError:
                response = "HTTP/1.1 404 Not Found\r\nContent-Type: text/plain\r\nContent-Length: 13\r\n\r\nFile Not Found"
            except Exception as e_file:
                print(f"Error serving index.html: {e_file}")
                response = "HTTP/1.1 500 Internal Server Error\r\nContent-Type: text/plain\r\nContent-Length: 21\r\n\r\nInternal Server Error"
        else: # Default to 404 for other paths for simplicity
            response = "HTTP/1.1 404 Not Found\r\nContent-Type: text/plain\r\nContent-Length: 9\r\n\r\nNot Found"

        writer.write(response.encode())
        await writer.drain()
    except ConnectionResetError:
        print("HTTP Client connection reset.") # Common if browser closes connection
    except Exception as e_http:
        print(f"HTTP server error: {e_http}")
    finally:
        if not writer.is_closing():
            writer.close()
            await writer.wait_closed()

# --- WebSocket Server for UI ---
async def ui_websocket_handler(websocket: websockets.WebSocketServerProtocol, path: str):
    global ui_websocket_clients, worker_id, current_p2p_peer_id, p2p_udp_transport, current_p2p_peer_addr
    ui_websocket_clients.add(websocket)
    print(f"Worker '{worker_id}': UI WebSocket client connected from {websocket.remote_address}")
    try:
        # Send initial info to UI
        await websocket.send(json.dumps({
            "type": "init_info", 
            "worker_id": worker_id,
            "p2p_peer_id": current_p2p_peer_id # Send current peer if already connected
        }))

        async for message_raw in websocket:
            print(f"Worker '{worker_id}': Message from UI WebSocket: {message_raw}")
            try:
                message = json.loads(message_raw)
                msg_type = message.get("type")

                if msg_type == "send_p2p_message":
                    content = message.get("content")
                    if content and current_p2p_peer_addr and p2p_udp_transport:
                        print(f"Worker '{worker_id}': Sending P2P UDP message '{content}' to peer {current_p2p_peer_id} at {current_p2p_peer_addr}")
                        p2p_message = {
                            "type": "chat_message", # Define a simple protocol
                            "from_worker_id": worker_id,
                            "content": content
                        }
                        p2p_udp_transport.sendto(json.dumps(p2p_message).encode(), current_p2p_peer_addr)
                    elif not current_p2p_peer_addr:
                         await websocket.send(json.dumps({"type": "error", "message": "Not connected to a P2P peer."}))
                    elif not content:
                         await websocket.send(json.dumps({"type": "error", "message": "Cannot send empty message."}))

                elif msg_type == "ui_client_hello": # UI confirms it's ready
                    print(f"Worker '{worker_id}': UI Client says hello.")
                    # Resend peer info in case it connected after P2P link was established
                    if current_p2p_peer_id:
                         await websocket.send(json.dumps({
                            "type": "p2p_status_update", 
                            "message": f"P2P link active with {current_p2p_peer_id[:8]}...",
                            "peer_id": current_p2p_peer_id
                        }))


            except json.JSONDecodeError:
                print(f"Worker '{worker_id}': UI WebSocket received non-JSON: {message_raw}")
            except Exception as e_ui_msg:
                print(f"Worker '{worker_id}': Error processing UI WebSocket message: {e_ui_msg}")
    except websockets.exceptions.ConnectionClosed:
        print(f"Worker '{worker_id}': UI WebSocket client {websocket.remote_address} disconnected.")
    except Exception as e_ui_conn:
        print(f"Worker '{worker_id}': Error with UI WebSocket connection {websocket.remote_address}: {e_ui_conn}")
    finally:
        ui_websocket_clients.remove(websocket)
        print(f"Worker '{worker_id}': UI WebSocket client {websocket.remote_address} removed.")


# --- Asyncio Datagram Protocol for P2P UDP Listener (from Step 3B) ---
class P2PUDPProtocol(asyncio.DatagramProtocol):
    def __init__(self, worker_id_val: str):
        self.worker_id = worker_id_val
        self.transport: Optional[asyncio.DatagramTransport] = None
        print(f"Worker '{self.worker_id}': P2PUDPProtocol instance created.")

    def connection_made(self, transport: asyncio.DatagramTransport):
        global p2p_udp_transport 
        self.transport = transport
        p2p_udp_transport = transport 
        local_addr = transport.get_extra_info('sockname')
        print(f"Worker '{self.worker_id}': P2P UDP listener active on {local_addr} (Internal Port: {INTERNAL_UDP_PORT}).")

    def datagram_received(self, data: bytes, addr: Tuple[str, int]):
        global current_p2p_peer_addr, current_p2p_peer_id
        message_str = data.decode(errors='ignore')
        print(f"Worker '{self.worker_id}': == UDP Packet Received from {addr}: '{message_str}' ==")
        
        # If this is the peer we expect, update current_p2p_peer_addr if not set or changed
        # This helps in sending replies if the source port changes mid-communication (less common with EIM)
        # current_p2p_peer_addr = addr 

        try:
            p2p_message = json.loads(message_str)
            msg_type = p2p_message.get("type")
            from_id = p2p_message.get("from_worker_id")
            content = p2p_message.get("content")

            if msg_type == "chat_message":
                print(f"Worker '{self.worker_id}': Received P2P chat message from '{from_id}': '{content}'")
                # Forward to all connected UI clients
                for ui_client_ws in list(ui_websocket_clients):
                    asyncio.create_task(ui_client_ws.send(json.dumps({
                        "type": "p2p_message_received",
                        "from_peer_id": from_id,
                        "content": content
                    })))
            # Handle PING/PONG if you keep them for basic connectivity test
            elif "P2P_PING_FROM_" in message_str: # Legacy from 3B, can be replaced by JSON chat
                print(f"Worker '{self.worker_id}': !!! P2P UDP Ping (legacy) received from {addr} !!!")
                # ... (optional PONG response) ...
        except json.JSONDecodeError:
            print(f"Worker '{self.worker_id}': Received non-JSON UDP packet from {addr}: {message_str}")


    def error_received(self, exc: Exception): # ... (same as 3B) ...
        print(f"Worker '{self.worker_id}': P2P UDP listener error: {exc}")
    def connection_lost(self, exc: Optional[Exception]): # ... (same as 3B) ...
        global p2p_udp_transport
        print(f"Worker '{self.worker_id}': P2P UDP listener connection lost: {exc if exc else 'Closed normally'}")
        if self.transport == p2p_udp_transport: p2p_udp_transport = None

# --- STUN Discovery (largely same as Step 3B) ---
async def discover_and_report_stun_udp_endpoint(websocket_conn_to_rendezvous):
    # ... (This function remains the same as your Step 3B version in holepunch/main.py) ...
    # It uses a temporary socket for STUN and sends "update_udp_endpoint" to Rendezvous.
    # Ensure it sets global `our_stun_discovered_udp_ip` and `our_stun_discovered_udp_port`.
    global our_stun_discovered_udp_ip, our_stun_discovered_udp_port, worker_id
    temp_stun_socket_for_discovery = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        temp_stun_socket_for_discovery.bind(("0.0.0.0", 0))
        local_stun_query_port = temp_stun_socket_for_discovery.getsockname()[1]
        stun_host = os.environ.get("STUN_HOST", DEFAULT_STUN_HOST)
        stun_port = int(os.environ.get("STUN_PORT", DEFAULT_STUN_PORT))
        print(f"Worker '{worker_id}': Attempting STUN discovery via {stun_host}:{stun_port} using temp local UDP port {local_stun_query_port}.")
        nat_type, external_ip, external_port = stun.get_ip_info(
            source_ip="0.0.0.0", source_port=local_stun_query_port, 
            stun_host=stun_host, stun_port=stun_port
        )
        print(f"Worker '{worker_id}': STUN: NAT='{nat_type}', External IP='{external_ip}', Port={external_port}")
        if external_ip and external_port:
            our_stun_discovered_udp_ip = external_ip
            our_stun_discovered_udp_port = external_port
            await websocket_conn_to_rendezvous.send(json.dumps({
                "type": "update_udp_endpoint", "udp_ip": external_ip, "udp_port": external_port
            }))
            print(f"Worker '{worker_id}': Sent STUN UDP endpoint ({external_ip}:{external_port}) to Rendezvous.")
            return True
        return False
    except Exception as e: print(f"Worker '{worker_id}': STUN error: {type(e).__name__} - {e}"); return False
    finally: 
        if temp_stun_socket_for_discovery: temp_stun_socket_for_discovery.close()

# --- UDP Hole Punching (sends initial pings - can be adapted to send first chat message) ---
async def start_udp_hole_punch(peer_udp_ip: str, peer_udp_port: int, peer_worker_id: str):
    # ... (This function remains similar to Step 3B, sending initial UDP packets) ...
    # It now primarily serves to "wake up" the NAT path. Actual chat data is sent on demand.
    global worker_id, stop_signal_received, p2p_udp_transport, current_p2p_peer_addr, current_p2p_peer_id
    
    if not p2p_udp_transport:
        print(f"Worker '{worker_id}': UDP transport not ready for hole punch to '{peer_worker_id}'.")
        return
    
    current_p2p_peer_id = peer_worker_id
    current_p2p_peer_addr = (peer_udp_ip, peer_udp_port) # Store for sending chat messages

    print(f"Worker '{worker_id}': Starting UDP hole punch PINGs towards '{peer_worker_id}' at {current_p2p_peer_addr}")
    
    for i in range(1, 4): # Send a few initial pings
        if stop_signal_received: break
        try:
            message_content = f"P2P_HOLE_PUNCH_PING_FROM_{worker_id}_NUM_{i}"
            p2p_udp_transport.sendto(message_content.encode(), current_p2p_peer_addr)
            print(f"Worker '{worker_id}': Sent UDP Hole Punch PING {i} to {current_p2p_peer_addr}")
        except Exception as e:
            print(f"Worker '{worker_id}': Error sending UDP Hole Punch PING {i}: {e}")
        await asyncio.sleep(0.5)
    
    print(f"Worker '{worker_id}': Finished UDP Hole Punch PING burst to '{peer_worker_id}'.")
    # Notify UI that P2P link is now (hopefully) active
    for ui_client_ws in list(ui_websocket_clients):
        asyncio.create_task(ui_client_ws.send(json.dumps({
            "type": "p2p_status_update", 
            "message": f"P2P link attempt initiated with {peer_worker_id[:8]}...",
            "peer_id": peer_worker_id
            })))


# --- Main WebSocket Connection Logic to Rendezvous (adapting from Step 3B) ---
async def connect_to_rendezvous(rendezvous_ws_url: str, http_server_port: int):
    global stop_signal_received, p2p_udp_transport, INTERNAL_UDP_PORT, ui_websocket_clients
    # ... (Most of this function from your current `holepunch/main.py` (Step 3A/3B) remains the same) ...
    # Key changes:
    # 1. Start the asyncio HTTP server for index.html
    # 2. Start the asyncio WebSocket server for the UI
    # 3. The P2P UDP listener is started *after* STUN success.

    loop = asyncio.get_running_loop()

    # Start local HTTP server for index.html
    # The existing threaded health_check_server is on HTTP_PORT_FOR_UI (e.g. 8080)
    # If we want our UI on a *different* port or path, that's fine.
    # For Cloud Run, all traffic comes to PORT. We need path differentiation.
    # The health_check_server satisfies Cloud Run's need for *something* on PORT.
    # Our UI server (HTTP + WebSocket) could run on PORT, and differentiate by path.
    # Let's make the UI WebSocket server run on PORT as well, path /ui_ws
    # And the HTTP server for / also on PORT, serving index.html

    # This approach uses `websockets.serve` which includes its own HTTP handling for the WS upgrade.
    # For serving index.html, the existing threaded HTTP server is already there on $PORT.
    # We just need to make sure IT serves index.html at "/"
    # And our UI websocket server listens on $PORT at path "/ui_ws"

    # The `start_healthcheck_http_server` from your code needs modification to serve index.html at "/"
    # and 404 others, while our `ui_websocket_handler` is served by `websockets.serve` on a different path.
    # OR, use one server for both. FastAPI is good for this, but adds a dependency.
    # Let's try to make the existing threaded HTTP server smarter.
    
    # For this PoC, we'll keep the health_check_server simple (just OK for /)
    # and start a *separate* asyncio HTTP server for index.html, AND a separate UI WebSocket server.
    # This requires careful port management if running locally.
    # On Cloud Run, $PORT is king.
    # The `websockets` library can co-exist with an HTTP server by path.

    # The `websockets.serve` function handles the HTTP upgrade for WebSockets.
    # It can run on the same port as your main HTTP server if paths are distinct
    # or if the HTTP server knows to delegate WebSocket upgrade requests.
    # For simplicity, the `websockets.serve` will handle its own HTTP for the /ui_ws path.
    # The main HTTP health check is already running.
    
    # Start UI WebSocket Server (on the main $PORT, at path /ui_ws)
    # The `websockets` server needs to be started alongside the `connect_to_rendezvous` client logic.
    # This is tricky because `websockets.serve` is a long-running server.
    # We need to integrate all these async components.

    # --- This function will now be the main async orchestrator ---

    # 1. Start P2P UDP Listener (on INTERNAL_UDP_PORT)
    # This will be started *after* STUN discovery confirms we have an external endpoint
    p2p_listener_transport_local = None # Use local var for this instance of connect_to_rendezvous

    # --- WebSocket to Rendezvous ---
    # (Your existing loop from holepunch/main.py for connecting to Rendezvous)
    # ...
    ip_echo_service_url = "https://api.ipify.org" 
    ping_interval = float(os.environ.get("PING_INTERVAL_SEC", "25")) 
    ping_timeout = float(os.environ.get("PING_TIMEOUT_SEC", "25"))

    while not stop_signal_received:
        # ... (rest of the try/except block for websockets.connect from your current holepunch/main.py) ...
        try:
            async with websockets.connect(
                rendezvous_ws_url,
                ping_interval=ping_interval,
                ping_timeout=ping_timeout,
            ) as ws_to_rendezvous: # Renamed for clarity
                print(f"Worker '{worker_id}' connected to Rendezvous Service.")

                # Report HTTP-based IP (as in your current code)
                try:
                    response = requests.get(ip_echo_service_url, timeout=10)
                    response.raise_for_status()
                    http_public_ip = response.text.strip()
                    await ws_to_rendezvous.send(json.dumps({"type": "register_public_ip", "ip": http_public_ip}))
                    print(f"Worker '{worker_id}' sent HTTP-based IP ({http_public_ip}) to Rendezvous.")
                except Exception as e_http_ip: print(f"Worker '{worker_id}': Error sending HTTP IP: {e_http_ip}")
                
                # Discover and report STUN UDP endpoint
                stun_success = await discover_and_report_stun_udp_endpoint(ws_to_rendezvous)

                if stun_success and not p2p_listener_transport_local: # Start P2P UDP listener if STUN ok
                    try:
                        # Note: P2PUDPProtocol sets the global p2p_udp_transport on connection_made
                        _transport, _protocol = await loop.create_datagram_endpoint(
                            lambda: P2PUDPProtocol(worker_id),
                            local_addr=('0.0.0.0', INTERNAL_UDP_PORT)
                        )
                        p2p_listener_transport_local = _transport # Keep local ref for this connection cycle
                        await asyncio.sleep(0.1) # allow connection_made to run
                        if p2p_udp_transport:
                             print(f"Worker '{worker_id}': Asyncio P2P UDP listener started on 0.0.0.0:{INTERNAL_UDP_PORT}.")
                        else:
                             print(f"Worker '{worker_id}': P2P UDP listener transport not set after create_datagram_endpoint call.")
                    except Exception as e_udp_listen:
                        print(f"Worker '{worker_id}': Failed to start P2P UDP listener: {e_udp_listen}")
                
                # WebSocket receive loop (for messages from Rendezvous)
                while not stop_signal_received:
                    try:
                        message_raw = await asyncio.wait_for(ws_to_rendezvous.recv(), timeout=60.0)
                        # ... (Handle udp_endpoint_ack, echo_response, my_details_response as in your current code) ...
                        # ... (Handle p2p_connection_offer as in previous Step 3B plan) ...
                        print(f"Worker '{worker_id}': Message from Rendezvous: {message_raw}")
                        message_data = json.loads(message_raw)
                        msg_type = message_data.get("type")

                        if msg_type == "p2p_connection_offer":
                            peer_id = message_data.get("peer_worker_id")
                            peer_ip = message_data.get("peer_udp_ip")
                            peer_port = message_data.get("peer_udp_port")
                            if peer_id and peer_ip and peer_port:
                                print(f"Worker '{worker_id}': Received P2P offer for peer '{peer_id}' at {peer_ip}:{peer_port}")
                                if p2p_udp_transport and our_stun_discovered_udp_ip:
                                    asyncio.create_task(start_udp_hole_punch(peer_ip, int(peer_port), peer_id))
                                else:
                                    print(f"Worker '{worker_id}': Cannot P2P, UDP listener/STUN info not ready.")
                            # Other message handlers (ack, etc.)
                        elif msg_type == "udp_endpoint_ack":
                             print(f"Worker '{worker_id}': UDP Endpoint Ack: {message_data.get('status')}")
                        # ...etc
                    except asyncio.TimeoutError: pass
                    except websockets.exceptions.ConnectionClosed: break
                    except Exception as e_recv: print(f"Error in WS recv loop: {e_recv}"); break
                # End of inner while not stop_signal_received (WebSocket recv loop)
                if websockets.exceptions.ConnectionClosed: break # Exit outer loop if WS closed
            
        # ... (Outer WebSocket connection exception handling from your current code) ...
        except Exception as e_ws_connect:
            print(f"Worker '{worker_id}': Error in WebSocket connection loop: {e_ws_connect}. Retrying...")
        
        finally: # Cleanup for this specific WebSocket connection attempt
            if p2p_listener_transport_local: # Close UDP listener associated with this WS session
                print(f"Worker '{worker_id}': Closing P2P UDP transport from this WS session's finally block.")
                p2p_listener_transport_local.close()
                # If p2p_udp_transport is global and set by this, clear it
                if p2p_udp_transport == p2p_listener_transport_local:
                    p2p_udp_transport = None
                p2p_listener_transport_local = None
        
        if not stop_signal_received: await asyncio.sleep(10)
        else: break
    # End of outer while not stop_signal_received (main connection retry loop)

# --- Health Check Server (Threaded - Keep as is from your current code) ---
# This runs on $PORT and answers "/" for Cloud Run health checks.
def start_healthcheck_http_server_threaded():
    class _Handler(http.server.BaseHTTPRequestHandler):
        def do_GET(self):
            # Serve index.html for GET /
            if self.path == '/':
                try:
                    html_path = Path(__file__).parent / "index.html"
                    with open(html_path, "rb") as f: # Read as bytes
                        content = f.read()
                    self.send_response(200)
                    self.send_header("Content-Type", "text/html")
                    self.send_header("Content-Length", str(len(content)))
                    self.end_headers()
                    self.wfile.write(content)
                except FileNotFoundError:
                    self.send_response(404)
                    self.send_header("Content-Type", "text/plain")
                    self.end_headers()
                    self.wfile.write(b"index.html not found")
                return
            # Existing simple health check for other paths or if index.html fails
            self.send_response(200); self.send_header("Content-Type","text/plain"); self.end_headers(); self.wfile.write(b"OK (Health Check Server)")
        def log_message(self, format, *args): return # Suppress logs

    port = HTTP_PORT_FOR_UI # Use the $PORT from Cloud Run
    httpd = socketserver.TCPServer(("0.0.0.0", port), _Handler)
    threading.Thread(target=httpd.serve_forever, daemon=True).start()
    print(f"Worker '{worker_id}': Threaded HTTP server for index.html and health checks listening on 0.0.0.0:{port}")

async def main_async_runner():
    # This will run the Rendezvous client and the UI WebSocket server concurrently
    loop = asyncio.get_running_loop()

    # Start the UI WebSocket server (on $PORT, path /ui_ws)
    # The websockets.serve also handles HTTP requests for the WebSocket upgrade.
    # We need to ensure this doesn't conflict with the health check HTTP server on the same port.
    # The health check server is very basic. If `websockets.serve` can handle regular HTTP on other paths, great.
    # If not, they need different ports or the main HTTP server needs to proxy/delegate WS upgrades.

    # For Cloud Run, all traffic hits $PORT.
    # The `websockets.serve` will only respond to WebSocket upgrade requests on its specified path.
    # Other HTTP requests to $PORT (like "/") will be handled by our threaded HTTP server.
    
    # Start the UI WebSocket server
    # Note: websockets.serve() handles only WebSocket connections.
    # HTTP requests to this port not matching a WebSocket path will likely be rejected by it.
    # This is why the threaded HTTP server handles GET /.
    ui_ws_server = await websockets.serve(
        ui_websocket_handler, 
        "0.0.0.0", 
        HTTP_PORT_FOR_UI, # Run UI WebSocket on the same port as HTTP server
        subprotocols=["chat"], # Example subprotocol
        process_request=lambda path, headers: None if path == "/ui_ws" else (404, [], b"Not a WebSocket endpoint") # Only handle /ui_ws
    )
    print(f"Worker '{worker_id}': UI WebSocket server listening on 0.0.0.0:{HTTP_PORT_FOR_UI} at path /ui_ws")

    # Construct Rendezvous WebSocket URL (as in your existing __main__)
    rendezvous_base_url_env = os.environ.get("RENDEZVOUS_SERVICE_URL")
    if not rendezvous_base_url_env: # Should have been caught by __main__ but good to check
        print("CRITICAL: RENDEZVOUS_SERVICE_URL missing in main_async_runner."); return

    ws_scheme = "wss" if rendezvous_base_url_env.startswith("https://") else "ws"
    base_url_no_scheme = rendezvous_base_url_env.replace("https://", "").replace("http://", "")
    full_rendezvous_ws_url = f"{ws_scheme}://{base_url_no_scheme}/ws/register/{worker_id}"

    # Start the Rendezvous client connection
    rendezvous_client_task = asyncio.create_task(connect_to_rendezvous(full_rendezvous_ws_url, HTTP_PORT_FOR_UI))

    try:
        await rendezvous_client_task # Keep main running until client task finishes (e.g. on stop_signal)
    except asyncio.CancelledError:
        print(f"Worker '{worker_id}': Rendezvous client task was cancelled.")
    finally:
        ui_ws_server.close()
        await ui_ws_server.wait_closed()
        print(f"Worker '{worker_id}': UI WebSocket server stopped.")
        if p2p_udp_transport: # Ensure UDP is closed if Rendezvous client stops
            p2p_udp_transport.close()
            print(f"Worker '{worker_id}': P2P UDP transport closed from main_async_runner finally.")


if __name__ == "__main__":
    print(f"WORKER SCRIPT (ID: {worker_id}): Initializing...")
    
    # Start the threaded HTTP server for health checks and serving index.html
    start_healthcheck_http_server_threaded()

    rendezvous_base_url_env = os.environ.get("RENDEZVOUS_SERVICE_URL")
    if not rendezvous_base_url_env:
        print("CRITICAL ERROR: RENDEZVOUS_SERVICE_URL environment variable not set. Exiting worker.")
        exit(1) # Critical: Cannot operate without Rendezvous URL

    signal.signal(signal.SIGTERM, handle_shutdown_signal)
    signal.signal(signal.SIGINT, handle_shutdown_signal)

    try:
        asyncio.run(main_async_runner()) # Run the main async orchestrator
    except KeyboardInterrupt:
        print(f"Worker '{worker_id}' interrupted by user (KeyboardInterrupt in __main__).")
        stop_signal_received = True 
    except Exception as e_main_run:
        print(f"Worker '{worker_id}' CRITICAL ERROR in __main__ asyncio.run: {type(e_main_run).__name__} - {e_main_run}")
    finally:
        print(f"Worker '{worker_id}' main process (_main__) finished or exited.")
        # Ensure final cleanup, though handle_shutdown_signal and task finally blocks should cover most.
```

### 4A.1.4. Worker Service `requirements.txt` (`holepunch/requirements.txt`)

No changes from Step 3B. `websockets` is already included.

```
websockets>=12.0
requests>=2.0.0 
pystun3>=1.1.6 
```

### 4A.1.5. Worker Service `Dockerfile.worker` (`holepunch/Dockerfile.worker`)

No changes needed from Step 3B (still `CMD ["python", "-u", "main.py"]`).

### 4A.1.6. Build and Re-deploy the Worker Service

1.  **Build Image (from `holepunch` directory):**
    ```bash
    # cd path/to/holepunch
    gcloud builds submit --region=$REGION \
        --tag ${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_WORKER_REPO_NAME}/${WORKER_SERVICE_NAME}:${WORKER_IMAGE_TAG_V5} . \
        --dockerfile=Dockerfile.worker
    ```
2.  **Re-deploy Worker Service:**
    The worker now serves HTTP/WebSocket for its UI, so `--allow-unauthenticated` is needed again if you want to access it directly from your browser without IAP or other auth.
    ```bash
    gcloud run deploy $WORKER_SERVICE_NAME \
        --project=$PROJECT_ID \
        --image=${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_WORKER_REPO_NAME}/${WORKER_SERVICE_NAME}:${WORKER_IMAGE_TAG_V5} \
        --platform=managed \
        --region=$REGION \
        --update-env-vars="RENDEZVOUS_SERVICE_URL=${RENDEZVOUS_SERVICE_URL},STUN_HOST=${STUN_HOST:-stun.l.google.com},STUN_PORT=${STUN_PORT:-19302},INTERNAL_UDP_PORT=${INTERNAL_UDP_PORT_ENV_VAR_VALUE:-8081}" \
        --allow-unauthenticated \
        --vpc-egress=all-traffic \
        --network=$VPC_NETWORK_NAME \
        --subnet=$SUBNET_NAME \
        --min-instances=2 \
        --max-instances=2 \
        --cpu-boost
    ```

-----

## Part 4A.2: Verification

1.  **Deploy/Update both services.**
2.  **Open the Public URL of Worker A in your browser.** You should see the `index.html` page.
      * The status should indicate it's trying to connect to its local backend WebSocket (`/ui_ws`).
      * Once connected, it should display its Worker ID.
      * If P2P pairing with Worker B happens (from Step 3B logic), the UI might update to show connected peer.
3.  **Open the Public URL of Worker B in another browser tab/window.** Same initial behavior.
4.  **Test Sending a Message (Worker A's UI):**
      * Type a message in Worker A's UI input field and click "Send".
      * **Worker A Logs:**
          * Message from UI WebSocket: `{"type": "send_p2p_message", "content": "your message"}`
          * `Sending P2P UDP message 'your message' to peer Worker_B_ID at PeerB_NAT_IP:PeerB_NAT_Port`
      * **Worker B Logs:**
          * **CRUCIAL:** `== UDP Packet Received from PeerA_NAT_IP:PeerA_NAT_Source_Port: '{"type": "chat_message", "from_worker_id": "Worker_A_ID", "content": "your message"}' ==`
          * `Received P2P chat message from 'Worker_A_ID': 'your message'`
5.  **Check Worker A's UI:** The message you sent should appear as a "local" message.
6.  **Check Worker B's UI:** For *this Step 4A*, Worker B's UI will **not** yet display the message received via UDP. We'll implement the P2P UDP -\> UI WebSocket bridge in Step 4B. However, Worker B's *Python logs* should show the UDP packet being received.

**Success for Step 4A means:**

  * Each worker serves its `index.html`.
  * The `index.html` JavaScript successfully connects to its worker's Python backend via a *local* WebSocket (`/ui_ws`).
  * Messages typed into Worker A's UI are sent to Worker A's Python backend.
  * Worker A's Python backend successfully sends these messages as UDP packets to Worker B's NAT endpoint.
  * Worker B's Python backend successfully receives these UDP packets and logs them.

This sets up the pathway for messages from UI to P2P UDP. The next step (4B) will complete the loop by taking UDP messages received by a worker and displaying them in its own UI.
</file>

<file path="rendezvous_service_code/Dockerfile.rendezvous">
# Use an official Python runtime as a parent image
FROM python:3.9-slim

# Set the working directory in the container
WORKDIR /app

# Copy the requirements file to the working directory
COPY requirements.txt .

# Install dependencies
# --no-cache-dir reduces image size
# --prefer-binary can speed up installs for packages with binary distributions
RUN pip install --no-cache-dir --prefer-binary -r requirements.txt

# Copy the application code into the container
COPY main.py .

# Make port 8080 available (Cloud Run default)
EXPOSE 8080
ENV PORT 8080

# Command to run the Uvicorn server for FastAPI
# --host 0.0.0.0 makes it accessible from outside the container
# --port $PORT uses the port specified by the environment variable (set by Cloud Run)
# Adding --log-level trace for verbose Uvicorn output
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8080", "--log-level", "trace"]
</file>

<file path="Dockerfile.worker">
# Use an official Python runtime as a parent image
FROM python:3.9-slim

# Set the working directory in the container
WORKDIR /app

# Copy the requirements file
COPY requirements.txt .

# Install dependencies
RUN pip install --no-cache-dir --prefer-binary -r requirements.txt

# Copy the application code
COPY main.py .
COPY index.html .

# This worker doesn't run a Gunicorn server anymore; it runs the main.py script directly.
# The PORT environment variable is not directly used by main.py unless you add server logic back.
# No EXPOSE needed if it's only an outbound client.

# Command to run the Python script
CMD ["python", "-u", "main.py"]
</file>

<file path="requirements.txt">
websockets>=12.0
requests>=2.0.0
# Flask    # Not needed anymore if we removed the Flask app 
pystun3>=1.1.6 
# Check for the latest stable version of pystun3
</file>

<file path="plann_step2.md">
Okay, this is an exciting next step\! Now that we've proven your "worker" Cloud Run service can present a stable public IP (via Cloud NAT), let's build the system that allows workers to discover each other.

This involves two main parts:

1.  **Creating a Rendezvous Service:** This is a new, central service that workers will connect to. It will learn about each worker's public NAT endpoint (`IP:Port`).
2.  **Modifying the Worker Service:** Your existing worker service will be updated to connect to this new Rendezvous service via WebSockets and register itself.

This `README.md` will guide you through this. I've been extra careful with library versions and syntax, referencing current best practices.

**Project ID:** `iceberg-eli`
**Region:** `us-central1` (continuing from previous setup)

-----

## README - Step 2: Rendezvous Service and Worker Registration

### Objective

This step aims to:

1.  Create and deploy a **Rendezvous Service** on Cloud Run. This service will accept WebSocket connections from workers, observe their public NAT IP address and port, and keep track of active workers.
2.  Modify the existing **Worker Service** (from Step 1) to:
      * Generate a unique ID for itself upon startup.
      * Connect to the Rendezvous Service via a WebSocket.
      * Register itself by sending its unique ID.
      * Maintain this WebSocket connection (with basic reconnection logic).

This lays the groundwork for peer discovery, which is essential for P2P hole punching.

### Prerequisites

1.  **Completion of Step 1:** You must have successfully completed the previous step where you set up the Worker Service with Cloud NAT and verified its public IP observation. The VPC, subnet, Cloud Router, and Cloud NAT gateway (`ip-worker-nat`) should still be in place.
2.  **gcloud SDK and Configuration:**
      * `gcloud` installed and authenticated.
      * Project set: `gcloud config set project iceberg-eli`
      * Default region set (optional, but helps): `gcloud config set compute/region us-central1`
3.  **APIs Enabled:** The same APIs from Step 1 should still be enabled:
    ```bash
    gcloud services enable \
        cloudbuild.googleapis.com \
        run.googleapis.com \
        compute.googleapis.com \
        artifactregistry.googleapis.com \
        iam.googleapis.com
    ```

-----

## Part 1: The Rendezvous Service

This is a **NEW** service you will create.

### 1.1. Define Shell Variables (for Rendezvous Service)

```bash
# Set your Project ID and Region if not already set
# export PROJECT_ID="your-gcp-project-id"
# export REGION="your-gcp-region" # e.g., us-central1

# Dynamically get Project ID and set Region (example for us-central1)
export PROJECT_ID=$(gcloud config get-value project)
export REGION="us-central1"

export AR_RENDEZVOUS_REPO_NAME="rendezvous-repo" # New Artifact Registry repo
export RENDEZVOUS_SERVICE_NAME="rendezvous-service" # New Cloud Run service name
export RENDEZVOUS_IMAGE_TAG_LATEST="latest" # Or your preferred tag

# Verify variables (optional)
# echo "PROJECT_ID: $PROJECT_ID, REGION: $REGION"
```

### 1.2. Rendezvous Service Code

Create a new directory for the Rendezvous service (e.g., `rendezvous_service_code`). Inside this directory, create the following files:

**`rendezvous_service_code/main.py`:**

```python
import asyncio
import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from typing import Dict, Tuple
import os
import json

app = FastAPI(title="Rendezvous Service")

# In-memory storage for connected workers.
# Format: {worker_id: {"public_ip": str, "public_port": int, "websocket": WebSocket}}
# WARNING: This is for PoC only. Data will be lost if the service restarts or scales to zero.
# For production, use an external store like Redis or Firestore.
connected_workers: Dict[str, Dict] = {}

@app.websocket("/ws/register/{worker_id}")
async def websocket_register_worker(websocket: WebSocket, worker_id: str):
    await websocket.accept()
    client_host = websocket.client.host
    client_port = websocket.client.port
    
    print(f"Worker '{worker_id}' connecting from {client_host}:{client_port}")

    if worker_id in connected_workers:
        print(f"Worker '{worker_id}' re-connecting or duplicate ID detected.")
        old_ws = connected_workers[worker_id].get("websocket")
        if old_ws and hasattr(old_ws, 'client_state') and old_ws.client_state.value == 1: # WebSocketState.CONNECTED
             try:
                await old_ws.close(code=1000, reason="New connection from same worker ID")
             except Exception:
                pass 

    connected_workers[worker_id] = {
        "public_ip": client_host,
        "public_port": client_port,
        "websocket": websocket 
    }
    print(f"Worker '{worker_id}' registered with initial endpoint: {client_host}:{client_port}. Total workers: {len(connected_workers)}")

    try:
        while True:
            raw_data = await websocket.receive_text()
            print(f"Received raw message from '{worker_id}': {raw_data}")
            try:
                message = json.loads(raw_data)
                msg_type = message.get("type")

                if msg_type == "register_public_ip":
                    new_ip = message.get("ip")
                    if new_ip and worker_id in connected_workers: # Check worker_id still exists
                        print(f"Worker '{worker_id}' self-reported public IP: {new_ip}. Updating from {connected_workers[worker_id]['public_ip']}.")
                        connected_workers[worker_id]["public_ip"] = new_ip
                    elif not new_ip:
                        print(f"Worker '{worker_id}' sent register_public_ip message without an IP.")
                    # else: worker might have disconnected before IP update processed
                else:
                    print(f"Worker '{worker_id}' sent unhandled message type: {msg_type}")

            except json.JSONDecodeError:
                print(f"Worker '{worker_id}' sent non-JSON message: {raw_data}")
            except AttributeError: 
                print(f"Worker '{worker_id}' sent malformed JSON message: {raw_data}")
            except KeyError:
                 print(f"Worker '{worker_id}' no longer in connected_workers dictionary, could not update IP.")

    except WebSocketDisconnect:
        print(f"Worker '{worker_id}' disconnected from {client_host}:{client_port}.")
    except Exception as e:
        print(f"Error with worker '{worker_id}': {e}")
    finally:
        if worker_id in connected_workers and connected_workers[worker_id]["websocket"] == websocket:
            del connected_workers[worker_id]
            print(f"Worker '{worker_id}' de-registered. Total workers: {len(connected_workers)}")

@app.get("/")
async def read_root():
    return {"message": "Rendezvous Service is running. Connect via WebSocket at /ws/register/{worker_id}"}

@app.get("/debug/list_workers")
async def list_workers():
    workers_info = {}
    for worker_id, data_val in connected_workers.items():
        ws_object = data_val["websocket"]
        current_client_state_value = None
        is_connected = False
        if ws_object and hasattr(ws_object, 'client_state'):
            current_client_state = ws_object.client_state
            current_client_state_value = current_client_state.value
            is_connected = (current_client_state_value == 1) # WebSocketState.CONNECTED.value
            print(f"DEBUG: Worker {worker_id}, WebSocket object: {ws_object}, client_state enum: {current_client_state}, raw value: {current_client_state_value}")
        else:
            print(f"DEBUG: Worker {worker_id}, no WebSocket object or client_state found in data.")

        workers_info[worker_id] = {
            "public_ip": data_val["public_ip"],
            "public_port": data_val["public_port"],
            "connected": is_connected,
            "raw_state": current_client_state_value
        }
    return {"connected_workers_count": len(workers_info), "workers": workers_info}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=int(os.environ.get("PORT", 8080)))
```

**`rendezvous_service_code/requirements.txt`:**

```
fastapi>=0.111.0
uvicorn[standard]>=0.29.0 
# Using [standard] includes websockets and other useful dependencies for uvicorn.
# Check for latest stable versions if deploying much later.
```

*(Searched May 15, 2025: FastAPI 0.111.0 and Uvicorn 0.29.0 are current. Adjust if necessary based on actual release dates when you implement.)*

**`rendezvous_service_code/Dockerfile.rendezvous`:** (Note the specific Dockerfile name)

```dockerfile
# Use an official Python runtime as a parent image
FROM python:3.9-slim

# Set the working directory in the container
WORKDIR /app

# Copy the requirements file to the working directory
COPY requirements.txt .

# Install dependencies
# --no-cache-dir reduces image size
# --prefer-binary can speed up installs for packages with binary distributions
RUN pip install --no-cache-dir --prefer-binary -r requirements.txt

# Copy the application code into the container
COPY main.py .

# Make port 8080 available (Cloud Run default)
EXPOSE 8080
ENV PORT 8080

# Command to run the Uvicorn server for FastAPI
# --host 0.0.0.0 makes it accessible from outside the container
# --port $PORT uses the port specified by the environment variable (set by Cloud Run)
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8080"]
```

### 1.3. Build and Deploy the Rendezvous Service

1.  **Create Artifact Registry Repository (if you haven't for this service):**

    ```bash
    gcloud artifacts repositories create $AR_RENDEZVOUS_REPO_NAME \
        --project=$PROJECT_ID \
        --repository-format=docker \
        --location=$REGION \
        --description="Docker repository for Rendezvous Service"
    ```

    *(Ensure the Cloud Build service account has `roles/artifactregistry.writer` as done in Step 1. The command was `export PROJECT_NUMBER=$(gcloud projects describe $PROJECT_ID --format='value(projectNumber)'); gcloud projects add-iam-policy-binding $PROJECT_ID --member="serviceAccount:${PROJECT_NUMBER}@cloudbuild.gserviceaccount.com" --role="roles/artifactregistry.writer"`)*

2.  **Build and Push Image (from inside `rendezvous_service_code` directory):**

    ```bash
    # Ensure you are in the 'rendezvous_service_code' directory
    cd path/to/your/rendezvous_service_code 

    # Option 1: Using Cloud Build (recommended for CI/CD)
    # Temporarily rename Dockerfile.rendezvous to Dockerfile for Cloud Build, then rename back
    mv Dockerfile.rendezvous Dockerfile
    gcloud builds submit --region=$REGION \
        --tag ${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_RENDEZVOUS_REPO_NAME}/${RENDEZVOUS_SERVICE_NAME}:${RENDEZVOUS_IMAGE_TAG_LATEST} .
    mv Dockerfile Dockerfile.rendezvous

    # Option 2: Using local Docker (e.g., Docker Desktop)
    # If building on a non-amd64 machine (e.g., Apple M1/M2/M3), specify platform for Cloud Run compatibility:
    # docker buildx build --platform linux/amd64 -f Dockerfile.rendezvous -t ${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_RENDEZVOUS_REPO_NAME}/${RENDEZVOUS_SERVICE_NAME}:${RENDEZVOUS_IMAGE_TAG_LATEST} . --load
    # Otherwise, for amd64 machines:
    # docker build -f Dockerfile.rendezvous -t ${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_RENDEZVOUS_REPO_NAME}/${RENDEZVOUS_SERVICE_NAME}:${RENDEZVOUS_IMAGE_TAG_LATEST} .
    # docker push ${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_RENDEZVOUS_REPO_NAME}/${RENDEZVOUS_SERVICE_NAME}:${RENDEZVOUS_IMAGE_TAG_LATEST}
    ```

    *The `gcloud builds submit` command implicitly uses `Dockerfile` in the current directory. If your file is named `Dockerfile.rendezvous`, you either rename it for the build or use a `cloudbuild.yaml` to specify the Dockerfile name (not covered here). For local Docker builds, use the `-f` flag.* 

3.  **Deploy to Cloud Run:**
    The Rendezvous service needs to be publicly accessible.

    ```bash
    gcloud run deploy $RENDEZVOUS_SERVICE_NAME \
        --project=$PROJECT_ID \
        --image=${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_RENDEZVOUS_REPO_NAME}/${RENDEZVOUS_SERVICE_NAME}:${RENDEZVOUS_IMAGE_TAG_LATEST} \
        --platform=managed \
        --region=$REGION \
        --allow-unauthenticated \
        --session-affinity # Enable session affinity for WebSockets (good practice)
                           # --min-instances=1 # Optional: consider for production to reduce cold starts
    ```

      * `--session-affinity`: Helps ensure that subsequent requests from the same client (important for WebSocket re-establishment or related HTTP calls) are routed to the same Cloud Run instance, if you scale the Rendezvous service.
      * Note the URL of the deployed Rendezvous Service. You'll need it for the worker.

-----

## Part 2: Modified Worker Service

Now, we modify your existing `ip-worker-service` (from the `holepunch` directory in your provided files) to connect to the Rendezvous service.

### 2.1. Define Shell Variables (for Worker Service - some are from Step 1)

```bash
# Ensure PROJECT_ID and REGION are set (as in Part 1.1)
# export PROJECT_ID=$(gcloud config get-value project)
# export REGION="us-central1"

export AR_WORKER_REPO_NAME="ip-worker-repo" # Existing Artifact Registry repo from Step 1
export WORKER_SERVICE_NAME="ip-worker-service" # Existing Cloud Run service from Step 1
export WORKER_IMAGE_TAG_V2="v2" # Or a newer tag like v3, v4, etc. for new worker image versions

# You will need the URL of the deployed Rendezvous Service from Part 1.3.
# Option 1: Set it manually after noting it from Rendezvous deployment output.
# export RENDEZVOUS_SERVICE_URL="YOUR_RENDEZVOUS_SERVICE_URL_HERE"

# Option 2: Dynamically fetch the Rendezvous Service URL (if already deployed and variables are set):
# Ensure $RENDEZVOUS_SERVICE_NAME, $REGION, and $PROJECT_ID are correctly set.
# export RENDEZVOUS_SERVICE_URL=$(gcloud run services describe $RENDEZVOUS_SERVICE_NAME --platform managed --region $REGION --project $PROJECT_ID --format 'value(status.url)')

# IMPORTANT: Before deploying the worker, ensure RENDEZVOUS_SERVICE_URL is set correctly.
# You can verify by echoing it:
# echo "Rendezvous URL for Worker: $RENDEZVOUS_SERVICE_URL"
```

**ACTION: Replace `YOUR_RENDEZVOUS_SERVICE_URL_HERE` with the actual URL after deploying the Rendezvous service, or ensure the dynamic fetch command works.**

### 2.2. Worker Service Code Updates

Modify the files in your original `holepunch` directory (or a copy).

**`holepunch/main.py` (Modified Worker):**

```python
import asyncio
import os
import uuid
import websockets # Using the 'websockets' library
import signal # For graceful shutdown
import threading # For health check server
import http.server # For health check server
import socketserver # For health check server
import requests # For ipify.org
import json # For WebSocket messages

# This worker primarily functions as a WebSocket client.
# A minimal HTTP server is run in a background thread for Cloud Run health checks.

worker_id = str(uuid.uuid4())
stop_signal_received = False

def handle_shutdown_signal(signum, frame):
    global stop_signal_received
    print(f"Shutdown signal ({signum}) received. Attempting to close WebSocket connection.")
    stop_signal_received = True

async def connect_to_rendezvous(rendezvous_ws_url: str):
    global stop_signal_received
    print(f"WORKER CONNECT_TO_RENDEZVOUS: Entered function for URL: {rendezvous_ws_url}. stop_signal_received={stop_signal_received}")
    print(f"Worker '{worker_id}' attempting to connect to Rendezvous: {rendezvous_ws_url}")
    
    ip_echo_service_url = "https://api.ipify.org"
    # Default ping interval (seconds), can be overridden by environment variable
    ping_interval = float(os.environ.get("PING_INTERVAL_SEC", "25"))
    ping_timeout = float(os.environ.get("PING_TIMEOUT_SEC", "25"))

    while not stop_signal_received:
        try:
            async with websockets.connect(
                rendezvous_ws_url,
                ping_interval=ping_interval, # Send pings to keep connection alive
                ping_timeout=ping_timeout
            ) as websocket:
                print(f"Worker '{worker_id}' connected to Rendezvous.")

                try:
                    print(f"Worker '{worker_id}' fetching its public IP from {ip_echo_service_url}...")
                    response = requests.get(ip_echo_service_url, timeout=10)
                    response.raise_for_status()
                    public_ip = response.text.strip()
                    print(f"Worker '{worker_id}' identified public IP as: {public_ip}")
                    await websocket.send(json.dumps({
                        "type": "register_public_ip",
                        "ip": public_ip
                    }))
                    print(f"Worker '{worker_id}' sent public IP to Rendezvous.")
                except requests.exceptions.RequestException as e:
                    print(f"Worker '{worker_id}': Error fetching/sending public IP: {e}. Will rely on Rendezvous observed IP.")

                while not stop_signal_received:
                    try:
                        message = await asyncio.wait_for(websocket.recv(), timeout=max(30.0, ping_interval + ping_timeout + 5))
                        print(f"Received message from Rendezvous: {message}")
                    except asyncio.TimeoutError:
                        # No message received, pings are handling keepalive.
                        pass 
                    except websockets.exceptions.ConnectionClosed:
                        print(f"Worker '{worker_id}': Rendezvous WebSocket connection closed by server.")
                        break 

        except websockets.exceptions.ConnectionClosedOK:
            print(f"Worker '{worker_id}': Rendezvous WebSocket connection closed gracefully by server.")
        except websockets.exceptions.InvalidURI:
            print(f"Worker '{worker_id}': Invalid Rendezvous WebSocket URI: {rendezvous_ws_url}. Exiting.")
            return 
        except ConnectionRefusedError:
            print(f"Worker '{worker_id}': Connection to Rendezvous refused. Retrying in 10 seconds...")
        except Exception as e: # Catch other websocket errors like handshake timeouts
            print(f"Worker '{worker_id}': Error connecting/communicating with Rendezvous: {e}. Retrying in 10 seconds...")
        
        if not stop_signal_received:
            await asyncio.sleep(10) 
        else:
            break 

    print(f"Worker '{worker_id}' has stopped WebSocket connection attempts.")

# Minimal health-check HTTP server (as per Update 2025-05-16)
def start_healthcheck_http_server():
    class _Handler(http.server.BaseHTTPRequestHandler):
        def do_GET(self): self.send_response(200); self.send_header("Content-Type","text/plain"); self.end_headers(); self.wfile.write(b"OK")
        def log_message(self, format, *args): return
    port = int(os.environ.get("PORT", 8080))
    httpd = socketserver.TCPServer(("0.0.0.0", port), _Handler)
    threading.Thread(target=httpd.serve_forever, daemon=True).start()
    print(f"Health-check HTTP server listening on 0.0.0.0:{port}")

start_healthcheck_http_server()
print("HEALTHCHECK SERVER STARTED --- WORKER MAIN SCRIPT CONTINUING...")

if __name__ == "__main__":
    print("WORKER SCRIPT: Inside __main__ block.")
    rendezvous_base_url = os.environ.get("RENDEZVOUS_SERVICE_URL")
    if not rendezvous_base_url:
        print("Error: RENDEZVOUS_SERVICE_URL environment variable not set. Exiting.")
        exit(1)

    if rendezvous_base_url.startswith("http://"):
        rendezvous_ws_url_constructed = rendezvous_base_url.replace("http://", "ws://", 1)
    elif rendezvous_base_url.startswith("https://"):
        rendezvous_ws_url_constructed = rendezvous_base_url.replace("https://", "wss://", 1)
    else:
        rendezvous_ws_url_constructed = rendezvous_base_url 

    full_rendezvous_ws_url = f"{rendezvous_ws_url_constructed}/ws/register/{worker_id}"
    print(f"WORKER SCRIPT: About to call asyncio.run(connect_to_rendezvous) for URL: {full_rendezvous_ws_url}")
    
    signal.signal(signal.SIGTERM, handle_shutdown_signal)
    signal.signal(signal.SIGINT, handle_shutdown_signal)

    try:
        asyncio.run(connect_to_rendezvous(full_rendezvous_ws_url))
    except KeyboardInterrupt:
        print(f"Worker '{worker_id}' interrupted by user. Shutting down.")
    finally:
        print(f"Worker '{worker_id}' main process finished.")
```

**`holepunch/requirements.txt` (Worker):**

```
websockets>=12.0
requests>=2.0.0 # For ipify.org
```

*(Note: `requests` was re-added. Original comment about Flask removal is still valid.)*

**`holepunch/Dockerfile.worker`:** (Note the specific Dockerfile name)

```dockerfile
# Use an official Python runtime as a parent image
FROM python:3.9-slim

# Set the working directory in the container
WORKDIR /app

# Copy the requirements file
COPY requirements.txt .

# Install dependencies
RUN pip install --no-cache-dir --prefer-binary -r requirements.txt

# Copy the application code
COPY main.py .

# This worker doesn't run a Gunicorn server anymore; it runs the main.py script directly.
# No EXPOSE needed if it's only an outbound client.
# Using -u for unbuffered Python output, ensuring logs appear promptly in Cloud Run.
CMD ["python", "-u", "main.py"]
```

**Update (2025-05-16): Cloud Run health-check compatibility**  
Cloud Run expects every service revision to start an HTTP server that listens on the port provided in the `PORT` environment variable (default `8080`).  
Because our worker is a long-running WebSocket _client_ with no HTTP endpoints, Cloud Run would mark the revision unhealthy. To satisfy the default health-check we now start a **minimal background HTTP server** inside `main.py`. It responds with `200 OK` to any path and has negligible overhead. This tiny server is implemented with Python's standard `http.server` in a daemon thread and does **not** interfere with the worker's WebSocket logic.

You can see this in the top of the new `main.py` (look for `start_healthcheck_http_server()`).

### 2.3. Build and Re-deploy the Worker Service

1.  **Build and Push Worker Image (from inside `holepunch` directory):**

    ```bash
    # Ensure you are in the 'holepunch' directory (project root for this service)
    # cd path/to/your/holepunch 

    # Option 1: Using Cloud Build (recommended for CI/CD)
    # Temporarily rename Dockerfile.worker to Dockerfile for Cloud Build, then rename back
    mv Dockerfile.worker Dockerfile
    gcloud builds submit --region=$REGION \
        --tag ${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_WORKER_REPO_NAME}/${WORKER_SERVICE_NAME}:${WORKER_IMAGE_TAG_V2} .
    mv Dockerfile Dockerfile.worker

    # Option 2: Using local Docker (e.g., Docker Desktop)
    # If building on a non-amd64 machine (e.g., Apple M1/M2/M3), specify platform for Cloud Run compatibility:
    # docker buildx build --platform linux/amd64 -f Dockerfile.worker -t ${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_WORKER_REPO_NAME}/${WORKER_SERVICE_NAME}:${WORKER_IMAGE_TAG_V2} . --load
    # Otherwise, for amd64 machines:
    # docker build -f Dockerfile.worker -t ${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_WORKER_REPO_NAME}/${WORKER_SERVICE_NAME}:${WORKER_IMAGE_TAG_V2} .
    # docker push ${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_WORKER_REPO_NAME}/${WORKER_SERVICE_NAME}:${WORKER_IMAGE_TAG_V2}
    ```
    *(Note: `AR_WORKER_REPO_NAME` is `ip-worker-repo` from Step 1. Ensure it exists. Use a new tag like `:v3`, `:v4` for subsequent builds.)*

2.  **Re-deploy the Worker Service to Cloud Run:**
    This updates your existing `ip-worker-service`. Crucially, we add the `RENDEZVOUS_SERVICE_URL` environment variable.
    **Remember to set `RENDEZVOUS_SERVICE_URL` in your shell first, from Part 2.1\!**

    ```bash
    if [ -z "$RENDEZVOUS_SERVICE_URL" ] || [ "$RENDEZVOUS_SERVICE_URL" == "YOUR_RENDEZVOUS_SERVICE_URL_HERE" ]; then
        echo "Error: RENDEZVOUS_SERVICE_URL is not set. Please set it to the URL of your deployed Rendezvous service."
        exit 1
    fi

    gcloud run deploy $WORKER_SERVICE_NAME \
        --project=$PROJECT_ID \
        --image=${REGION}-docker.pkg.dev/${PROJECT_ID}/${AR_WORKER_REPO_NAME}/${WORKER_SERVICE_NAME}:${WORKER_IMAGE_TAG_V2} \
        --platform=managed \
        --region=$REGION \
        --set-env-vars="RENDEZVOUS_SERVICE_URL=${RENDEZVOUS_SERVICE_URL}" \
        # To update/add multiple env vars, including for WebSocket pings:
        # --update-env-vars="RENDEZVOUS_SERVICE_URL=${RENDEZVOUS_SERVICE_URL},PING_INTERVAL_SEC=25,PING_TIMEOUT_SEC=25" \
        --vpc-egress=all-traffic \
        --network=$VPC_NETWORK_NAME \ # From Step 1: ip-worker-vpc
        --subnet=$SUBNET_NAME \       # From Step 1: ip-worker-subnet
        --max-instances=2 # Example: deploy 2 worker instances to see them both register
                          # Keep other settings like CPU allocation as default or adjust as needed.
                          # Allow unauthenticated is not needed as this service doesn't serve inbound HTTP now.
                          # If you removed the Flask server, you might want to configure a startup CPU boost
                          # or set min-instances to 1 if you want it always running,
                          # but for this PoC, on-demand startup is fine.
    ```

      * The `--allow-unauthenticated` flag is removed as this worker no longer serves HTTP traffic. It only makes outbound connections.
      * Ensure the VPC and Subnet names (`$VPC_NETWORK_NAME`, `$SUBNET_NAME`) are the same as those used in Step 1 for Cloud NAT.

-----

## Part 3: Verification

1.  **Check Rendezvous Service Logs:**

      * Go to Google Cloud Console -> Cloud Run -> Select `rendezvous-service`.
      * View its logs. You should see messages like:
        `Worker 'xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx' connecting from <INITIAL_IP>:<INITIAL_PORT>`
        `Worker 'xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx' registered with initial endpoint: <INITIAL_IP>:<INITIAL_PORT>. Total workers: X`
        `Received raw message from 'xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx': {"type": "register_public_ip", "ip": "<ACTUAL_PUBLIC_NAT_IP>"}`
        `Worker 'xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx' self-reported public IP: <ACTUAL_PUBLIC_NAT_IP>. Updating from <INITIAL_IP>.`
      * The `<ACTUAL_PUBLIC_NAT_IP>` should be one of the IPs of your `ip-worker-nat` Cloud NAT gateway.
      * When calling `/debug/list_workers`, you might see `DEBUG: Worker xxxxxxxx..., client_state raw value: 1` (or similar for `WebSocketState.CONNECTED`).

2.  **Check Worker Service Logs:**
      * (`CMD ["python", "-u", "main.py"]` in `Dockerfile.worker` helps ensure logs appear promptly.)
      * Go to Google Cloud Console -> Cloud Run -> Select `ip-worker-service`.
      * View its logs. Each worker instance should log:
        `HEALTHCHECK SERVER STARTED --- WORKER MAIN SCRIPT CONTINUING...`
        `WORKER SCRIPT: Inside __main__ block.`
        `WORKER SCRIPT: About to call asyncio.run(connect_to_rendezvous) for URL: wss://<your-rendezvous-url>/ws/register/<worker_id>`
        `WORKER CONNECT_TO_RENDEZVOUS: Entered function for URL: ...`
        `Worker '...' attempting to connect to Rendezvous: ...`
        (Potentially some connection timeout/retry messages)
        `Worker '...' connected to Rendezvous.`
        `Worker '...' fetching its public IP from https://api.ipify.org...`
        `Worker '...' identified public IP as: <ACTUAL_PUBLIC_NAT_IP>`
        `Worker '...' sent public IP to Rendezvous.`

3.  **Use the Rendezvous Debug Endpoint (Optional but Recommended):**

      * If you deployed the Rendezvous service and it's running with `--allow-unauthenticated`, open its public URL in a browser and navigate to `/debug/list_workers`.
      * Example: `https://rendezvous-service-xxxx-uc.a.run.app/debug/list_workers`
      * This should show a JSON list of registered workers, e.g.:
        ```json
        {
          "connected_workers_count": 1,
          "workers": {
            "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx": {
              "public_ip": "<ACTUAL_PUBLIC_NAT_IP>",
              "public_port": <WORKER_INITIALLY_OBSERVED_PORT>,
              "connected": true,
              "raw_state": 1 
            }
          }
        }
        ```
      * `public_ip` should be the self-reported external NAT IP.
      * `connected` should be `true` if the WebSocket is active (derived from `raw_state == 1`).

-----
</file>

<file path="rendezvous_service_code/main.py">
import asyncio
import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from typing import Dict, Optional, List, Tuple
import os
import json

app = FastAPI(title="Rendezvous Service")

# connected_workers structure from Step 3A:
# { worker_id: { "websocket_observed_ip": ..., "websocket_observed_port": ...,
#                "websocket": WebSocket, 
#                "stun_reported_udp_ip": ..., "stun_reported_udp_port": ...,
#                "http_reported_public_ip": ... # Optional, if you keep it
#              }}
connected_workers: Dict[str, Dict] = {}

# List of worker_ids that have reported UDP info and are waiting for a peer
workers_ready_for_pairing: List[str] = []

async def attempt_to_pair_workers(newly_ready_worker_id: str):
    global workers_ready_for_pairing, connected_workers

    # Ensure the worker trying to pair is valid
    if newly_ready_worker_id not in connected_workers or \
       not connected_workers[newly_ready_worker_id].get("stun_reported_udp_ip"):
        print(f"Pairing: Worker '{newly_ready_worker_id}' not in connected_workers or no UDP info. Cannot initiate pairing.")
        if newly_ready_worker_id in workers_ready_for_pairing:
            workers_ready_for_pairing.remove(newly_ready_worker_id)
        return

    # Add the new worker to the ready list if not already present
    if newly_ready_worker_id not in workers_ready_for_pairing:
        workers_ready_for_pairing.append(newly_ready_worker_id)
        print(f"Rendezvous: Worker '{newly_ready_worker_id}' added to ready_for_pairing list. Current list: {workers_ready_for_pairing}")

    # Attempt to find a pair if there are at least two workers ready
    if len(workers_ready_for_pairing) < 2:
        print(f"Rendezvous: Not enough workers ready for pairing ({len(workers_ready_for_pairing)}). Waiting for more.")
        return

    # Take the first two distinct workers from the list for pairing
    # This is a simple strategy; more complex ones could be used (e.g., oldest, random)
    peer_a_id = None
    peer_b_id = None

    temp_ready_list = list(workers_ready_for_pairing) # Iterate over a copy
    for i in range(len(temp_ready_list)):
        potential_a = temp_ready_list[i]
        if potential_a in connected_workers and connected_workers[potential_a].get("stun_reported_udp_ip"):
            for j in range(i + 1, len(temp_ready_list)):
                potential_b = temp_ready_list[j]
                if potential_b in connected_workers and connected_workers[potential_b].get("stun_reported_udp_ip"):
                    peer_a_id = potential_a
                    peer_b_id = potential_b
                    break
            if peer_a_id and peer_b_id: # Found a pair
                break
        else: # Clean up stale entry from original list
            if potential_a in workers_ready_for_pairing:
                 workers_ready_for_pairing.remove(potential_a)


    if peer_a_id and peer_b_id:
        # Found a pair! Remove both from the ready list.
        workers_ready_for_pairing.remove(peer_a_id)
        workers_ready_for_pairing.remove(peer_b_id)
        print(f"Rendezvous: Pairing Worker '{peer_a_id}' with Worker '{peer_b_id}'. Updated ready list: {workers_ready_for_pairing}")

        peer_a_data = connected_workers.get(peer_a_id)
        peer_b_data = connected_workers.get(peer_b_id)

        if not (peer_a_data and peer_b_data and 
                peer_a_data.get("stun_reported_udp_ip") and peer_a_data.get("stun_reported_udp_port") and
                peer_b_data.get("stun_reported_udp_ip") and peer_b_data.get("stun_reported_udp_port") and
                peer_a_data.get("websocket") and peer_b_data.get("websocket")):
            print(f"Pairing Error: Data integrity issue for pairing {peer_a_id} and {peer_b_id}. One might have disconnected or lost info.")
            # Re-add valid ones if they were prematurely removed, or let them re-register
            return

        peer_a_ws = peer_a_data["websocket"]
        peer_b_ws = peer_b_data["websocket"]

        offer_to_b_payload = { 
            "type": "p2p_connection_offer",
            "peer_worker_id": peer_a_id,
            "peer_udp_ip": peer_a_data["stun_reported_udp_ip"],
            "peer_udp_port": peer_a_data["stun_reported_udp_port"]
        }
        offer_to_a_payload = { 
            "type": "p2p_connection_offer",
            "peer_worker_id": peer_b_id,
            "peer_udp_ip": peer_b_data["stun_reported_udp_ip"],
            "peer_udp_port": peer_b_data["stun_reported_udp_port"]
        }

        try:
            # Send B's info to A
            if hasattr(peer_a_ws, 'client_state') and peer_a_ws.client_state.value == 1:
                await peer_a_ws.send_text(json.dumps(offer_to_a_payload))
                print(f"Rendezvous: Sent connection offer to Worker '{peer_a_id}' (for peer '{peer_b_id}').")
            else:
                print(f"Rendezvous: Worker '{peer_a_id}' WebSocket not open. Cannot send offer.")

            # Send A's info to B
            if hasattr(peer_b_ws, 'client_state') and peer_b_ws.client_state.value == 1:
                await peer_b_ws.send_text(json.dumps(offer_to_b_payload))
                print(f"Rendezvous: Sent connection offer to Worker '{peer_b_id}' (for peer '{peer_a_id}').")
            else:
                print(f"Rendezvous: Worker '{peer_b_id}' WebSocket not open. Cannot send offer.")
        except Exception as e:
            print(f"Rendezvous: Error sending P2P connection offers: {e}")
    else:
        print(f"Rendezvous: No suitable peer found in ready_for_pairing list for newly ready worker '{newly_ready_worker_id}'.")

@app.websocket("/ws/register/{worker_id}")
async def websocket_register_worker(websocket: WebSocket, worker_id: str):
    global connected_workers, workers_ready_for_pairing
    await websocket.accept()
    client_host = websocket.client.host 
    client_port = websocket.client.port 
    
    print(f"Worker '{worker_id}' connecting from WebSocket endpoint: {client_host}:{client_port}")

    if worker_id in connected_workers:
        print(f"Worker '{worker_id}' re-connecting or duplicate ID detected.")
        old_ws_data = connected_workers.get(worker_id)
        if old_ws_data:
            old_ws = old_ws_data.get("websocket")
            if old_ws and hasattr(old_ws, 'client_state') and old_ws.client_state.value == 1:
                 try: await old_ws.close(code=1000, reason="New connection from same worker ID")
                 except Exception: pass
        if worker_id in workers_ready_for_pairing: 
            workers_ready_for_pairing.remove(worker_id)

    connected_workers[worker_id] = {
        "websocket_observed_ip": client_host, 
        "websocket_observed_port": client_port, 
        "websocket": websocket,
        "stun_reported_udp_ip": None, 
        "stun_reported_udp_port": None,
        "http_reported_public_ip": None # Field for general public IP
    }
    print(f"Worker '{worker_id}' registered. WebSocket EP: {client_host}:{client_port}. Total: {len(connected_workers)}")

    try:
        while True: 
            raw_data = await websocket.receive_text()
            print(f"Rendezvous: Received raw message from '{worker_id}': {raw_data}")
            try:
                message = json.loads(raw_data)
                msg_type = message.get("type")

                if msg_type == "register_public_ip":
                    new_ip = message.get("ip")
                    if new_ip and worker_id in connected_workers:
                        connected_workers[worker_id]["http_reported_public_ip"] = new_ip 
                        print(f"Worker '{worker_id}' reported HTTP-based public IP: {new_ip}")
                
                elif msg_type == "update_udp_endpoint":
                    udp_ip = message.get("udp_ip")
                    udp_port = message.get("udp_port")
                    if udp_ip and udp_port and worker_id in connected_workers:
                        connected_workers[worker_id]["stun_reported_udp_ip"] = udp_ip
                        connected_workers[worker_id]["stun_reported_udp_port"] = int(udp_port)
                        print(f"Worker '{worker_id}' updated STUN UDP endpoint to: {udp_ip}:{udp_port}")
                        await websocket.send_text(json.dumps({"type": "udp_endpoint_ack", "status": "success"}))
                        await attempt_to_pair_workers(worker_id)
                    else:
                        await websocket.send_text(json.dumps({"type": "udp_endpoint_ack", "status": "error", "detail": "Missing IP or Port"}))
                
                elif msg_type == "echo_request": 
                    payload = message.get("payload", "")
                    await websocket.send_text(json.dumps({
                        "type": "echo_response",
                        "original_payload": payload,
                        "processed_by_rendezvous": f"Rendezvous processed: '{payload.upper()}' for worker {worker_id}"
                    }))
                else:
                    print(f"Rendezvous: Worker '{worker_id}' sent unhandled message type: {msg_type}")

            except json.JSONDecodeError: print(f"Rendezvous: Worker '{worker_id}' sent non-JSON: {raw_data}")
            except AttributeError: print(f"Rendezvous: Worker '{worker_id}' sent malformed JSON: {raw_data}")
            except KeyError: print(f"Rendezvous: Worker '{worker_id}' no longer in dict.")

    except WebSocketDisconnect:
        print(f"Worker '{worker_id}' disconnected from WebSocket EP: {client_host}:{client_port}.")
    except Exception as e:
        print(f"Error with worker '{worker_id}' WebSocket: {e}")
    finally:
        if worker_id in connected_workers and connected_workers[worker_id].get("websocket") == websocket:
            del connected_workers[worker_id]
            print(f"Worker '{worker_id}' de-registered. Total: {len(connected_workers)}")
        if worker_id in workers_ready_for_pairing: 
            workers_ready_for_pairing.remove(worker_id)
            print(f"Worker '{worker_id}' removed from pending pairing list due to disconnect.")

@app.get("/")
async def read_root():
    return {"message": "Rendezvous Service is running."}

@app.get("/debug/list_workers")
async def list_workers():
    workers_info = {}
    for worker_id_key, data_val in list(connected_workers.items()):
        ws_object = data_val.get("websocket")
        is_connected = False
        if ws_object and hasattr(ws_object, 'client_state') and ws_object.client_state.value == 1:
            is_connected = True
        
        workers_info[worker_id_key] = {
            "websocket_observed_ip": data_val.get("websocket_observed_ip"),
            "websocket_observed_port": data_val.get("websocket_observed_port"),
            "http_reported_public_ip": data_val.get("http_reported_public_ip"),
            "stun_reported_udp_ip": data_val.get("stun_reported_udp_ip"),
            "stun_reported_udp_port": data_val.get("stun_reported_udp_port"),
            "websocket_connected": is_connected
        }
    return {"connected_workers_count": len(workers_info), "workers": workers_info, "ready_for_pairing_count": len(workers_ready_for_pairing), "ready_list": workers_ready_for_pairing}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=int(os.environ.get("PORT", 8080)), log_level="trace")
</file>

<file path="main.py">
import asyncio
import os
import uuid
import websockets # For Rendezvous client AND UI server
import signal
import threading
import http.server 
import socketserver 
import requests 
import json
import socket
import stun # pystun3
from typing import Optional, Tuple, Set, Dict
from pathlib import Path
from websockets.server import serve as websockets_serve
from websockets.http import Headers
import time # For benchmark timing
import base64 # For encoding benchmark payload

# --- Global Variables ---
worker_id = str(uuid.uuid4())
stop_signal_received = False
p2p_udp_transport: Optional[asyncio.DatagramTransport] = None
our_stun_discovered_udp_ip: Optional[str] = None
our_stun_discovered_udp_port: Optional[int] = None
current_p2p_peer_id: Optional[str] = None
current_p2p_peer_addr: Optional[Tuple[str, int]] = None

DEFAULT_STUN_HOST = os.environ.get("STUN_HOST", "stun.l.google.com")
DEFAULT_STUN_PORT = int(os.environ.get("STUN_PORT", "19302"))
INTERNAL_UDP_PORT = int(os.environ.get("INTERNAL_UDP_PORT", "8081"))
HTTP_PORT_FOR_UI = int(os.environ.get("PORT", 8080))

ui_websocket_clients: Set[websockets.WebSocketServerProtocol] = set()

# Benchmark related globals
benchmark_sessions: Dict[str, Dict] = {} # Key: peer_addr_str, Value: {received_bytes, received_chunks, start_time, total_chunks (from sender)}
BENCHMARK_CHUNK_SIZE = 1024 # 1KB

def handle_shutdown_signal(signum, frame):
    global stop_signal_received, p2p_udp_transport
    print(f"Shutdown signal ({signum}) received. Worker '{worker_id}' attempting graceful shutdown.")
    stop_signal_received = True
    if p2p_udp_transport:
        try: p2p_udp_transport.close(); print(f"Worker '{worker_id}': P2P UDP transport closed.")
        except Exception as e: print(f"Worker '{worker_id}': Error closing P2P UDP transport: {e}")
    for ws_client in list(ui_websocket_clients):
        asyncio.create_task(ws_client.close(reason="Server shutting down"))

async def process_http_request(path: str, request_headers: Headers) -> Optional[Tuple[int, Headers, bytes]]:
    if path == "/ui_ws": return None  
    if path == "/":
        try:
            html_path = Path(__file__).parent / "index.html"
            with open(html_path, "rb") as f: content = f.read()
            headers = Headers([("Content-Type", "text/html"), ("Content-Length", str(len(content)))])
            return (200, headers, content)
        except FileNotFoundError: return (404, [("Content-Type", "text/plain")], b"index.html not found")
        except Exception as e_file: print(f"Error serving index.html: {e_file}"); return (500, [("Content-Type", "text/plain")], b"Internal Server Error")
    elif path == "/health": return (200, [("Content-Type", "text/plain")], b"OK")
    else: return (404, [("Content-Type", "text/plain")], b"Not Found")

async def benchmark_send_udp_data(target_ip: str, target_port: int, size_kb: int, ui_ws: websockets.WebSocketServerProtocol):
    global worker_id, p2p_udp_transport
    if not (p2p_udp_transport and current_p2p_peer_addr):
        err_msg = "P2P UDP transport or peer address not available for benchmark."
        print(f"Worker '{worker_id}': {err_msg}")
        await ui_ws.send(json.dumps({"type": "benchmark_status", "message": f"Error: {err_msg}"}))
        return

    print(f"Worker '{worker_id}': Starting P2P UDP Benchmark: Sending {size_kb}KB to {target_ip}:{target_port}")
    await ui_ws.send(json.dumps({"type": "benchmark_status", "message": f"Benchmark Send: Starting to send {size_kb}KB..."}))

    num_chunks = size_kb
    dummy_chunk_content = b'B' * (BENCHMARK_CHUNK_SIZE - 50) # Approx to leave room for JSON overhead
    dummy_chunk_b64 = base64.b64encode(dummy_chunk_content).decode('ascii')
    
    start_time = time.monotonic()
    bytes_sent = 0

    try:
        for i in range(num_chunks):
            if stop_signal_received or ui_ws.closed:
                print(f"Worker '{worker_id}': Benchmark send cancelled (stop_signal or UI disconnected).")
                await ui_ws.send(json.dumps({"type": "benchmark_status", "message": "Benchmark send cancelled."}))
                break
            
            payload = {"type": "benchmark_chunk", "seq": i, "payload": dummy_chunk_b64, "from_worker_id": worker_id}
            data_to_send = json.dumps(payload).encode()
            p2p_udp_transport.sendto(data_to_send, (target_ip, target_port))
            bytes_sent += len(data_to_send)
            if (i + 1) % (num_chunks // 10 if num_chunks >=10 else 1) == 0: # Update UI every 10% or each chunk
                progress_msg = f"Benchmark Send: Sent {i+1}/{num_chunks} chunks ({bytes_sent / 1024:.2f} KB)..."
                print(f"Worker '{worker_id}': {progress_msg}")
                await ui_ws.send(json.dumps({"type": "benchmark_status", "message": progress_msg}))
            await asyncio.sleep(0.001) # Tiny sleep to yield control, prevent overwhelming the loop/network too fast
        else: # If loop completed without break
            # Send benchmark end marker
            end_payload = {"type": "benchmark_end", "total_chunks": num_chunks, "from_worker_id": worker_id}
            p2p_udp_transport.sendto(json.dumps(end_payload).encode(), (target_ip, target_port))
            print(f"Worker '{worker_id}': Sent benchmark_end marker to {target_ip}:{target_port}")

            end_time = time.monotonic()
            duration = end_time - start_time
            throughput_kbps = (bytes_sent / 1024) / duration if duration > 0 else 0
            final_msg = f"Benchmark Send Complete: Sent {bytes_sent / 1024:.2f} KB in {duration:.2f}s. Throughput: {throughput_kbps:.2f} KB/s"
            print(f"Worker '{worker_id}': {final_msg}")
            await ui_ws.send(json.dumps({"type": "benchmark_status", "message": final_msg}))

    except Exception as e:
        error_msg = f"Benchmark Send Error: {type(e).__name__} - {e}"
        print(f"Worker '{worker_id}': {error_msg}")
        if not ui_ws.closed:
            await ui_ws.send(json.dumps({"type": "benchmark_status", "message": f"Error: {error_msg}"}))

async def ui_websocket_handler(websocket: websockets.WebSocketServerProtocol, path: str):
    global ui_websocket_clients, worker_id, current_p2p_peer_id, p2p_udp_transport, current_p2p_peer_addr
    ui_websocket_clients.add(websocket)
    print(f"Worker '{worker_id}': UI WebSocket client connected from {websocket.remote_address}")
    try:
        await websocket.send(json.dumps({"type": "init_info", "worker_id": worker_id, "p2p_peer_id": current_p2p_peer_id}))
        async for message_raw in websocket:
            print(f"Worker '{worker_id}': Message from UI WebSocket: {message_raw}")
            try:
                message = json.loads(message_raw)
                msg_type = message.get("type")
                if msg_type == "send_p2p_message":
                    content = message.get("content")
                    if content and current_p2p_peer_addr and p2p_udp_transport:
                        print(f"Worker '{worker_id}': Sending P2P UDP message '{content}' to peer {current_p2p_peer_id} at {current_p2p_peer_addr}")
                        p2p_message = {"type": "chat_message", "from_worker_id": worker_id, "content": content}
                        p2p_udp_transport.sendto(json.dumps(p2p_message).encode(), current_p2p_peer_addr)
                    elif not current_p2p_peer_addr: await websocket.send(json.dumps({"type": "error", "message": "Not connected to a P2P peer."}))
                    elif not content: await websocket.send(json.dumps({"type": "error", "message": "Cannot send empty message."}))
                elif msg_type == "ui_client_hello":
                    print(f"Worker '{worker_id}': UI Client says hello.")
                    if current_p2p_peer_id:
                         await websocket.send(json.dumps({"type": "p2p_status_update", "message": f"P2P link active with {current_p2p_peer_id[:8]}...", "peer_id": current_p2p_peer_id}))
                elif msg_type == "start_benchmark_send": # NEW
                    size_kb = message.get("size_kb", 1024)
                    if current_p2p_peer_addr:
                        print(f"Worker '{worker_id}': UI requested benchmark send of {size_kb}KB to {current_p2p_peer_id}")
                        asyncio.create_task(benchmark_send_udp_data(current_p2p_peer_addr[0], current_p2p_peer_addr[1], size_kb, websocket))
                    else:
                        await websocket.send(json.dumps({"type": "benchmark_status", "message": "Error: No P2P peer to start benchmark with."}))
            except json.JSONDecodeError: print(f"Worker '{worker_id}': UI WebSocket received non-JSON: {message_raw}")
            except Exception as e_ui_msg: print(f"Worker '{worker_id}': Error processing UI WebSocket message: {e_ui_msg}")
    except websockets.exceptions.ConnectionClosed: print(f"Worker '{worker_id}': UI WebSocket client {websocket.remote_address} disconnected.")
    except Exception as e_ui_conn: print(f"Worker '{worker_id}': Error with UI WebSocket connection {websocket.remote_address}: {e_ui_conn}")
    finally:
        ui_websocket_clients.remove(websocket)
        print(f"Worker '{worker_id}': UI WebSocket client {websocket.remote_address} removed.")

class P2PUDPProtocol(asyncio.DatagramProtocol):
    def __init__(self, worker_id_val: str):
        self.worker_id = worker_id_val
        self.transport: Optional[asyncio.DatagramTransport] = None
        print(f"Worker '{self.worker_id}': P2PUDPProtocol instance created.")
    def connection_made(self, transport: asyncio.DatagramTransport):
        global p2p_udp_transport 
        self.transport = transport
        p2p_udp_transport = transport 
        local_addr = transport.get_extra_info('sockname')
        print(f"Worker '{self.worker_id}': P2P UDP listener active on {local_addr} (Internal Port: {INTERNAL_UDP_PORT}).")
    def datagram_received(self, data: bytes, addr: Tuple[str, int]):
        global current_p2p_peer_addr, current_p2p_peer_id, benchmark_sessions
        print(f"Worker '{self.worker_id}': ENTERED datagram_received from {addr}. Raw data length: {len(data)}")
        message_str = data.decode(errors='ignore')
        try:
            p2p_message = json.loads(message_str)
            msg_type = p2p_message.get("type")
            from_id = p2p_message.get("from_worker_id")
            if msg_type == "chat_message":
                content = p2p_message.get("content")
                print(f"Worker '{self.worker_id}': Received P2P chat message from '{from_id}': '{content}'")
                print(f"WORKER '{self.worker_id}': Current ui_websocket_clients: {list(ui_websocket_clients)}")
                print(f"WORKER '{self.worker_id}': Forwarding to {len(ui_websocket_clients)} UI clients.")
                for ui_client_ws in list(ui_websocket_clients): 
                    print(f"WORKER '{self.worker_id}': Attempting to send to UI client: {ui_client_ws.remote_address}")
                    asyncio.create_task(ui_client_ws.send(json.dumps({"type": "p2p_message_received", "from_peer_id": from_id, "content": content})))
            elif msg_type == "p2p_test_data": # Legacy, can remove if benchmark uses benchmark_chunk
                test_data_content = p2p_message.get("data")
                print(f"Worker '{self.worker_id}': +++ P2P_TEST_DATA RECEIVED from '{from_id}': '{test_data_content}' +++")
            elif msg_type == "benchmark_chunk": # NEW
                seq = p2p_message.get("seq", -1)
                payload_b64 = p2p_message.get("payload", "")
                # payload_bytes = base64.b64decode(payload_b64) # Not strictly needed to decode on receiver for throughput test
                peer_addr_str = str(addr)
                if peer_addr_str not in benchmark_sessions:
                    benchmark_sessions[peer_addr_str] = {"received_bytes": 0, "received_chunks": 0, "start_time": time.monotonic(), "total_chunks": -1, "from_worker_id": from_id}
                session = benchmark_sessions[peer_addr_str]
                session["received_bytes"] += len(message_str) # Approx size of JSON string
                session["received_chunks"] += 1
                if session["received_chunks"] % 100 == 0: # Log progress periodically
                    print(f"Worker '{self.worker_id}': Benchmark data received from {from_id}@{peer_addr_str}: {session['received_chunks']} chunks, {session['received_bytes']/1024:.2f} KB")
            elif msg_type == "benchmark_end": # NEW
                total_chunks_sent = p2p_message.get("total_chunks", 0)
                peer_addr_str = str(addr)
                if peer_addr_str in benchmark_sessions:
                    session = benchmark_sessions[peer_addr_str]
                    session["total_chunks"] = total_chunks_sent
                    duration = time.monotonic() - session["start_time"]
                    throughput_kbps = (session["received_bytes"] / 1024) / duration if duration > 0 else 0
                    status_msg = f"Benchmark Receive from {session['from_worker_id']} Complete: Received {session['received_chunks']}/{total_chunks_sent} chunks ({session['received_bytes']/1024:.2f} KB) in {duration:.2f}s. Throughput: {throughput_kbps:.2f} KB/s"
                    print(f"Worker '{self.worker_id}': {status_msg}")
                    for ui_client_ws in list(ui_websocket_clients):
                        asyncio.create_task(ui_client_ws.send(json.dumps({"type": "benchmark_status", "message": status_msg})))
                    del benchmark_sessions[peer_addr_str] # Clear session
                else:
                    print(f"Worker '{self.worker_id}': Received benchmark_end from unknown session/peer {addr}")     
            elif "P2P_PING_FROM_" in message_str: print(f"Worker '{self.worker_id}': !!! P2P UDP Ping (legacy) received from {addr} !!!")
        except json.JSONDecodeError: print(f"Worker '{self.worker_id}': Received non-JSON UDP packet from {addr}: {message_str}")
    def error_received(self, exc: Exception): print(f"Worker '{self.worker_id}': P2P UDP listener error: {exc}")
    def connection_lost(self, exc: Optional[Exception]): 
        global p2p_udp_transport
        print(f"Worker '{self.worker_id}': P2P UDP listener connection lost: {exc if exc else 'Closed normally'}")
        if self.transport == p2p_udp_transport: p2p_udp_transport = None

async def discover_and_report_stun_udp_endpoint(websocket_conn_to_rendezvous):
    global our_stun_discovered_udp_ip, our_stun_discovered_udp_port, worker_id
    temp_stun_socket_for_discovery = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    try:
        temp_stun_socket_for_discovery.bind(("0.0.0.0", 0))
        local_stun_query_port = temp_stun_socket_for_discovery.getsockname()[1]
        stun_host = os.environ.get("STUN_HOST", DEFAULT_STUN_HOST)
        stun_port = int(os.environ.get("STUN_PORT", DEFAULT_STUN_PORT))
        print(f"Worker '{worker_id}': Attempting STUN discovery via {stun_host}:{stun_port} using temp local UDP port {local_stun_query_port}.")
        try:
            nat_type, external_ip, external_port = stun.get_ip_info(stun_host=stun_host, stun_port=stun_port)
            print(f"Worker '{worker_id}': STUN: NAT='{nat_type}', External IP='{external_ip}', Port={external_port}")
        except Exception as stun_e: print(f"Worker '{worker_id}': STUN get_ip_info failed: {type(stun_e).__name__} - {stun_e}"); return False 
        if external_ip and external_port:
            our_stun_discovered_udp_ip = external_ip; our_stun_discovered_udp_port = external_port
            await websocket_conn_to_rendezvous.send(json.dumps({"type": "update_udp_endpoint", "udp_ip": external_ip, "udp_port": external_port}))
            print(f"Worker '{worker_id}': Sent STUN UDP endpoint ({external_ip}:{external_port}) to Rendezvous."); return True
        else: print(f"Worker '{worker_id}': STUN discovery did not return valid external IP/Port."); return False
    except socket.gaierror as e_gaierror: print(f"Worker '{worker_id}': STUN host DNS resolution error: {e_gaierror}"); return False
    except Exception as e_outer: print(f"Worker '{worker_id}': Error in STUN setup: {type(e_outer).__name__} - {e_outer}"); return False
    finally: 
        if temp_stun_socket_for_discovery: temp_stun_socket_for_discovery.close()

async def start_udp_hole_punch(peer_udp_ip: str, peer_udp_port: int, peer_worker_id: str):
    global worker_id, stop_signal_received, p2p_udp_transport, current_p2p_peer_addr, current_p2p_peer_id
    if not p2p_udp_transport: print(f"Worker '{worker_id}': UDP transport not ready for hole punch to '{peer_worker_id}'."); return
    current_p2p_peer_id = peer_worker_id; current_p2p_peer_addr = (peer_udp_ip, peer_udp_port)
    print(f"Worker '{worker_id}': Starting UDP hole punch PINGs towards '{peer_worker_id}' at {current_p2p_peer_addr}")
    for i in range(1, 4):
        if stop_signal_received: break
        try:
            message_content = f"P2P_HOLE_PUNCH_PING_FROM_{worker_id}_NUM_{i}"
            p2p_udp_transport.sendto(message_content.encode(), current_p2p_peer_addr)
            print(f"Worker '{worker_id}': Sent UDP Hole Punch PING {i} to {current_p2p_peer_addr}")
        except Exception as e: print(f"Worker '{worker_id}': Error sending UDP Hole Punch PING {i}: {e}")
        await asyncio.sleep(0.5)
    print(f"Worker '{worker_id}': Finished UDP Hole Punch PING burst to '{peer_worker_id}'.")
    # Test data packet sending removed from here, will be initiated by UI action.
    for ui_client_ws in list(ui_websocket_clients):
        asyncio.create_task(ui_client_ws.send(json.dumps({"type": "p2p_status_update", "message": f"P2P link attempt initiated with {peer_worker_id[:8]}...", "peer_id": peer_worker_id})))

async def connect_to_rendezvous(rendezvous_ws_url: str):
    global stop_signal_received, p2p_udp_transport, INTERNAL_UDP_PORT, ui_websocket_clients, our_stun_discovered_udp_ip, our_stun_discovered_udp_port
    ip_echo_service_url = "https://api.ipify.org" 
    ping_interval = float(os.environ.get("PING_INTERVAL_SEC", "25")) 
    ping_timeout = float(os.environ.get("PING_TIMEOUT_SEC", "25")) 
    udp_listener_active = False
    loop = asyncio.get_running_loop()
    while not stop_signal_received:
        p2p_listener_transport_local_ref = None 
        try:
            async with websockets.connect(rendezvous_ws_url, ping_interval=ping_interval, ping_timeout=ping_timeout) as ws_to_rendezvous:
                print(f"Worker '{worker_id}' connected to Rendezvous Service.")
                try:
                    response = requests.get(ip_echo_service_url, timeout=10)
                    response.raise_for_status()
                    http_public_ip = response.text.strip()
                    await ws_to_rendezvous.send(json.dumps({"type": "register_public_ip", "ip": http_public_ip}))
                    print(f"Worker '{worker_id}' sent HTTP-based IP ({http_public_ip}) to Rendezvous.")
                except Exception as e_http_ip: print(f"Worker '{worker_id}': Error sending HTTP IP: {e_http_ip}")
                stun_success = await discover_and_report_stun_udp_endpoint(ws_to_rendezvous)
                if stun_success and not udp_listener_active:
                    try:
                        _transport, _protocol = await loop.create_datagram_endpoint(lambda: P2PUDPProtocol(worker_id), local_addr=('0.0.0.0', INTERNAL_UDP_PORT))
                        p2p_listener_transport_local_ref = _transport 
                        await asyncio.sleep(0.1) 
                        if p2p_udp_transport: print(f"Worker '{worker_id}': Asyncio P2P UDP listener appears started on 0.0.0.0:{INTERNAL_UDP_PORT}.")
                        else: print(f"Worker '{worker_id}': P2P UDP listener transport not set globally after create_datagram_endpoint.")
                        udp_listener_active = True
                    except Exception as e_udp_listen: print(f"Worker '{worker_id}': Failed to start P2P UDP listener: {e_udp_listen}")
                while not stop_signal_received:
                    try:
                        message_raw = await asyncio.wait_for(ws_to_rendezvous.recv(), timeout=60.0)
                        print(f"Worker '{worker_id}': Message from Rendezvous: {message_raw}")
                        message_data = json.loads(message_raw)
                        msg_type = message_data.get("type")
                        if msg_type == "p2p_connection_offer":
                            peer_id = message_data.get("peer_worker_id")
                            peer_ip = message_data.get("peer_udp_ip")
                            peer_port = message_data.get("peer_udp_port")
                            if peer_id and peer_ip and peer_port:
                                print(f"Worker '{worker_id}': Received P2P offer for peer '{peer_id}' at {peer_ip}:{peer_port}")
                                if udp_listener_active and our_stun_discovered_udp_ip:
                                    asyncio.create_task(start_udp_hole_punch(peer_ip, int(peer_port), peer_id))
                                else: print(f"Worker '{worker_id}': Cannot P2P, UDP listener/STUN info not ready.")
                        elif msg_type == "udp_endpoint_ack": print(f"Worker '{worker_id}': UDP Endpoint Ack: {message_data.get('status')}")
                        elif msg_type == "echo_response": print(f"Worker '{worker_id}': Echo Response: {message_data.get('processed_by_rendezvous')}")
                        else: print(f"Worker '{worker_id}': Unhandled message from Rendezvous: {msg_type}")
                    except asyncio.TimeoutError: pass
                    except websockets.exceptions.ConnectionClosed: print(f"Worker '{worker_id}': Rendezvous WS closed by server."); break
                    except Exception as e_recv: print(f"Error in WS recv loop: {e_recv}"); break
                if websockets.exceptions.ConnectionClosed: break 
        except Exception as e_ws_connect: print(f"Worker '{worker_id}': Error in WS connection loop: {type(e_ws_connect).__name__} - {e_ws_connect}. Retrying...")
        finally: 
            if p2p_listener_transport_local_ref: 
                print(f"Worker '{worker_id}': Closing local P2P UDP transport from this WS session.")
                p2p_listener_transport_local_ref.close()
                if p2p_udp_transport == p2p_listener_transport_local_ref: p2p_udp_transport = None
                udp_listener_active = False
        if not stop_signal_received: await asyncio.sleep(10)
        else: break

async def main_async_orchestrator():
    loop = asyncio.get_running_loop()
    main_server = await websockets_serve(
        ui_websocket_handler, "0.0.0.0", HTTP_PORT_FOR_UI,
        process_request=process_http_request,
        ping_interval=20, ping_timeout=20
    )
    print(f"Worker '{worker_id}': HTTP & UI WebSocket server listening on 0.0.0.0:{HTTP_PORT_FOR_UI}")
    print(f"  - Serving index.html at '/'")
    print(f"  - UI WebSocket at '/ui_ws'")
    print(f"  - Health check at '/health'")
    rendezvous_base_url_env = os.environ.get("RENDEZVOUS_SERVICE_URL")
    if not rendezvous_base_url_env: print("CRITICAL: RENDEZVOUS_SERVICE_URL missing in main_async_runner.")
    full_rendezvous_ws_url = ""
    if rendezvous_base_url_env: 
        ws_scheme = "wss" if rendezvous_base_url_env.startswith("https://") else "ws"
        base_url_no_scheme = rendezvous_base_url_env.replace("https://", "").replace("http://", "")
        full_rendezvous_ws_url = f"{ws_scheme}://{base_url_no_scheme}/ws/register/{worker_id}"
    rendezvous_client_task = asyncio.create_task(connect_to_rendezvous(full_rendezvous_ws_url))
    try: await rendezvous_client_task 
    except asyncio.CancelledError: print(f"Worker '{worker_id}': Rendezvous client task was cancelled.")
    finally:
        main_server.close()
        await main_server.wait_closed()
        print(f"Worker '{worker_id}': Main HTTP/UI WebSocket server stopped.")
        if p2p_udp_transport: p2p_udp_transport.close(); print(f"Worker '{worker_id}': P2P UDP transport closed from main_async_orchestrator finally.")

if __name__ == "__main__":
    print(f"WORKER SCRIPT (ID: {worker_id}): Initializing...")
    rendezvous_base_url_env = os.environ.get("RENDEZVOUS_SERVICE_URL")
    if not rendezvous_base_url_env: print("CRITICAL ERROR: RENDEZVOUS_SERVICE_URL environment variable not set. Exiting worker."); exit(1) 
    signal.signal(signal.SIGTERM, handle_shutdown_signal); signal.signal(signal.SIGINT, handle_shutdown_signal)
    try: asyncio.run(main_async_orchestrator())
    except KeyboardInterrupt: print(f"Worker '{worker_id}' interrupted by user."); stop_signal_received = True 
    except Exception as e_main_run: print(f"Worker '{worker_id}' CRITICAL ERROR in __main__: {type(e_main_run).__name__} - {e_main_run}")
    finally: print(f"Worker '{worker_id}' main EXIT.")
</file>

</files>
